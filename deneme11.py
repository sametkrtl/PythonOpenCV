import gradio as gr
import os
import time
import json
import pandas as pd
from datetime import datetime
from pathlib import Path
import tempfile
import shutil
from typing import List, Dict, Tuple, Optional
import logging
from faker import Faker
import random
import torch
from transformers import AutoTokenizer, AutoModelForTokenClassification, pipeline
import fitz  # PyMuPDF
import re
import numpy as np  # <-- EKLE
# ----------------------------------------------------
#  EnhancedAnonymizationApp  (Custom NER Model + Font Preservation)
# ----------------------------------------------------
class EnhancedAnonymizationApp:
    def __init__(self):
        # Logger ayarlarÄ±
        logging.basicConfig(level=logging.INFO)
        self.logger = logging.getLogger(__name__)
        
        # Model yolunu belirtin
        self.model_path = r"C:\Users\stj.skartal\Desktop\python\samet\ner_model_final"
        
        # NER pipeline'Ä±nÄ± yÃ¼kle
        self.ner_pipeline = self.load_custom_ner_model()
        
        # TutarlÄ± sahte Ã¼retim iÃ§in sabit seed
        self.global_seed = 123456
        random.seed(self.global_seed)

        # ğŸ‡¹ğŸ‡· TÃ¼rkÃ§e Faker Ã¶rneÄŸi
        self.fake = Faker("tr_TR")
        self.fake.seed_instance(self.global_seed)

        # Dizinleri oluÅŸtur
        for dir_name in ["uploads", "outputs", "logs", "temp"]:
            os.makedirs(dir_name, exist_ok=True)
        
        self.processing_stats = []
    
    def load_custom_ner_model(self):
        """Ã–zel NER modelini yÃ¼kle"""
        try:
            if not os.path.exists(self.model_path):
                self.logger.error(f"Model bulunamadÄ±: {self.model_path}")
                return None
            
            self.logger.info(f"Model yÃ¼kleniyor: {self.model_path}")
            
            # Tokenizer ve model yÃ¼kle
            tokenizer = AutoTokenizer.from_pretrained(self.model_path)
            model = AutoModelForTokenClassification.from_pretrained(self.model_path)
            
            # Pipeline oluÅŸtur
            ner_pipeline = pipeline(
                "ner",
                model=model,
                tokenizer=tokenizer,
                aggregation_strategy="simple",
                device=0 if torch.cuda.is_available() else -1
            )
            
            self.logger.info("Model baÅŸarÄ±yla yÃ¼klendi!")
            return ner_pipeline
            
        except Exception as e:
            self.logger.error(f"Model yÃ¼kleme hatasÄ±: {e}")
            return None
    
    def extract_text_with_positions(self, pdf_path: str) -> List[Dict]:
        try:
            doc = fitz.open(pdf_path)
            text_blocks = []
            for page_num in range(len(doc)):
                page = doc.load_page(page_num)
                blocks = page.get_text("dict")
                for block in blocks.get("blocks", []):
                    if "lines" in block:
                        for line in block["lines"]:
                            for span in line.get("spans", []):
                                text = (span.get("text") or "").strip()
                                if text:
                                    # --- TÄ°P DÃ–NÃœÅÃœMLERÄ°: float32 â†’ float, vs. ---
                                    bbox_raw = span.get("bbox", (0, 0, 0, 0))
                                    # fitz Rect ya da tuple olabilir
                                    if hasattr(bbox_raw, "__iter__"):
                                        bbox = tuple(float(x) for x in bbox_raw)
                                    else:
                                        # Rect ise
                                        try:
                                            bbox = (float(bbox_raw.x0), float(bbox_raw.y0),
                                                    float(bbox_raw.x1), float(bbox_raw.y1))
                                        except Exception:
                                            bbox = (0.0, 0.0, 0.0, 0.0)

                                    size = float(span.get("size", 12))
                                    flags = int(span.get("flags", 0))
                                    color = span.get("color", 0)
                                    # color bazen float olabilir; int'e gÃ¼venli dÃ¶ndÃ¼r
                                    try:
                                        color = int(color)
                                    except Exception:
                                        color = 0

                                    text_blocks.append({
                                        'page': int(page_num),
                                        'text': text,
                                        'bbox': bbox,               # artÄ±k saf Python float tuple
                                        'font': str(span.get("font") or "Unknown"),
                                        'size': size,
                                        'flags': flags,
                                        'color': color,
                                        'start_char': 0,
                                        'end_char': 0
                                    })
            doc.close()

            # global pozisyonlar
            char_position = 0
            for block in text_blocks:
                block['start_char'] = int(char_position)
                char_position += len(block['text']) + 1
                block['end_char'] = int(char_position - 1)

            return text_blocks
        except Exception as e:
            self.logger.error(f"Metin Ã§Ä±karma hatasÄ±: {e}")
            return []

     # --- EKLE: JSON gÃ¼venli dÃ¶nÃ¼ÅŸtÃ¼rÃ¼cÃ¼ ---
    def _json_safe(self, obj):
        # numpy sayÄ±larÄ±
        if isinstance(obj, (np.integer,)):
            return int(obj)
        if isinstance(obj, (np.floating,)):
            return float(obj)
        if isinstance(obj, (np.ndarray,)):
            return obj.tolist()
        # torch tensor
        if isinstance(obj, torch.Tensor):
            return obj.detach().cpu().tolist()
        # pandas zaman tipleri
        if isinstance(obj, pd.Timestamp):
            return obj.isoformat()
        # diÄŸer yaygÄ±n yapÄ±lar
        if isinstance(obj, (set, tuple)):
            return list(obj)
        if isinstance(obj, bytes):
            return obj.decode("utf-8", "ignore")
        # fitz.Rect veya benzeri
        try:
            from fitz import Rect
            if isinstance(obj, Rect):
                return [float(obj.x0), float(obj.y0), float(obj.x1), float(obj.y1)]
        except Exception:
            pass
        # son Ã§are: str
        return str(obj)
    def process_pdf_with_real_replacement(self, 
                                        pdf_file, 
                                        confidence_threshold: float,
                                        replacement_strategy: str,
                                        custom_replacements: str,
                                        enable_logging: bool,
                                        enable_debug: bool,
                                        conversion_method: str,
                                        progress=gr.Progress()) -> Tuple[Optional[str], str, str, pd.DataFrame, str]:
        """
        GeliÅŸmiÅŸ PDF iÅŸleme - GERÃ‡EK deÄŸiÅŸtirme ile (Custom NER + Font Preservation)
        """
        if pdf_file is None:
            return None, "âŒ LÃ¼tfen bir PDF dosyasÄ± yÃ¼kleyin.", "", pd.DataFrame(), ""
        
        if self.ner_pipeline is None:
            return None, "âŒ NER modeli yÃ¼klenemedi. Model yolunu kontrol edin.", "", pd.DataFrame(), ""
        
        debug_info = ""
        
        try:
            progress(0.05, desc="Dosya hazÄ±rlanÄ±yor...")
            
            # Dosya yollarÄ±
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            base_in = os.path.basename(pdf_file.name if hasattr(pdf_file, "name") else str(pdf_file))
            input_filename = f"input_{timestamp}_{base_in}"
            output_filename = f"anonymized_{timestamp}_{base_in}"
            
            input_path = os.path.join("uploads", input_filename)
            output_path = os.path.join("outputs", output_filename)
            
            # YÃ¼klenen dosyayÄ± kopyala
            shutil.copy2(pdf_file.name if hasattr(pdf_file, "name") else str(pdf_file), input_path)
            
            progress(0.1, desc="PDF analiz ediliyor...")
            
            # 1. PDF'ten metin ve pozisyonlarÄ± Ã§Ä±kar
            text_blocks = self.extract_text_with_positions(input_path)
            full_text = " ".join([block['text'] for block in text_blocks])
            
            if not full_text.strip():
                return None, "âš ï¸ PDF'den metin Ã§Ä±karÄ±lamadÄ±.", "", pd.DataFrame(), "Metin Ã§Ä±karÄ±lamadÄ±."
            
            progress(0.2, desc="NER analizi yapÄ±lÄ±yor...")
            
            # 2. Custom NER model ile analiz
            entities_detected = self.extract_entities_with_custom_model(full_text, text_blocks, confidence_threshold, progress)
            
            if not entities_detected:
                return None, "âš ï¸ PDF'de kiÅŸisel bilgi tespit edilmedi.", "", pd.DataFrame(), "HiÃ§bir entity tespit edilmedi."
            
            progress(0.4, desc="DeÄŸiÅŸtirme stratejisi uygulanÄ±yor...")
            
            # 3. DeÄŸiÅŸtirme stratejisini uygula
            processed_entities = self.apply_replacement_strategy(
                entities_detected, 
                replacement_strategy, 
                custom_replacements or ""
            )
            
            progress(0.5, desc="PDF'te deÄŸiÅŸiklikler uygulanÄ±yor...")
            
            # 4. Font korumalÄ± PDF deÄŸiÅŸtirme
            success = self.perform_font_preserving_replacement(
                input_path, 
                processed_entities, 
                output_path, 
                text_blocks,
                progress
            )
            
            if not success:
                return None, "âŒ PDF deÄŸiÅŸtirme iÅŸlemi baÅŸarÄ±sÄ±z oldu.", "", pd.DataFrame(), "DeÄŸiÅŸtirme baÅŸarÄ±sÄ±z"
            
            progress(0.8, desc="SonuÃ§lar doÄŸrulanÄ±yor...")
            
            # 5. DeÄŸiÅŸtirmeleri doÄŸrula
            validation_result = self.validate_pdf_changes(output_path, processed_entities)
            debug_info = self.format_debug_info(validation_result, processed_entities)
            
            progress(0.9, desc="Ä°statistikler oluÅŸturuluyor...")
            
            # 6. Ä°statistikleri oluÅŸtur
            stats_df = self.create_detailed_statistics(processed_entities, validation_result)
            summary = self.generate_detailed_summary(processed_entities, validation_result, input_filename)
            
            # 7. Loglama
            if enable_logging:
                self.log_processing_with_validation(input_filename, processed_entities, validation_result)
            
            progress(1.0, desc="TamamlandÄ±!")
            
            # BaÅŸarÄ± mesajÄ±
            success_rate = validation_result.get('successfully_replaced', 0)
            total_entities = len(processed_entities)
            status_msg = f"âœ… Ä°ÅŸlem tamamlandÄ±! {success_rate}/{total_entities} deÄŸiÅŸtirme baÅŸarÄ±lÄ±."
            
            return output_path, status_msg, summary, stats_df, (debug_info if enable_debug else "")
            
        except Exception as e:
            self.logger.error(f"PDF iÅŸleme hatasÄ±: {e}", exc_info=True)
            error_msg = f"âŒ Kritik hata: {str(e)}"
            return None, error_msg, "", pd.DataFrame(), f"Hata detayÄ±: {str(e)}"
    
    def extract_entities_with_custom_model(self, full_text: str, text_blocks: List[Dict], 
                                         confidence_threshold: float, progress) -> List[Dict]:
        """Custom NER model ile entity tespiti"""
        try:
            # Metni parÃ§alara bÃ¶l (model token limitini aÅŸmamak iÃ§in)
            max_length = 512
            text_chunks = []
            chunk_start = 0
            
            while chunk_start < len(full_text):
                chunk_end = min(chunk_start + max_length, len(full_text))
                
                # Kelime ortasÄ±nda kesmemek iÃ§in
                if chunk_end < len(full_text):
                    last_space = full_text.rfind(' ', chunk_start, chunk_end)
                    if last_space > chunk_start:
                        chunk_end = last_space
                
                chunk_text = full_text[chunk_start:chunk_end]
                text_chunks.append({
                    'text': chunk_text,
                    'start_offset': chunk_start,
                    'end_offset': chunk_end
                })
                chunk_start = chunk_end
            
            progress(0.25, desc=f"NER analizi ({len(text_chunks)} parÃ§a)...")
            
            all_entities = []
            
            # Her parÃ§a iÃ§in NER Ã§alÄ±ÅŸtÄ±r
            for i, chunk in enumerate(text_chunks):
                try:
                    results = self.ner_pipeline(chunk['text'])
                    
                    for result in results:
                        if result['score'] >= confidence_threshold:
                            # Global pozisyonu hesapla
                            entity_start = chunk['start_offset'] + result['start']
                            entity_end = chunk['start_offset'] + result['end']
                            
                            # Text block'ta karÅŸÄ±lÄ±k gelen pozisyonu bul
                            text_block_info = self.find_text_block_for_position(
                                entity_start, entity_end, text_blocks, full_text
                            )
                            
                            entity_dict = {
                                'entity': self.map_model_label_to_type(result['entity_group']),
                                'word': result['word'],
                                'start': entity_start,
                                'end': entity_end,
                                'score': result['score'],
                                'method': 'custom_ner',
                                'text_block_info': text_block_info
                            }
                            all_entities.append(entity_dict)
                
                except Exception as e:
                    self.logger.warning(f"Chunk {i} iÅŸlenirken hata: {e}")
                    continue
            
            progress(0.3, desc="Regex ile ek kontroller...")
            
            # Regex ile ek tespitler (TC kimlik vb.)
            regex_entities = self.perform_regex_detection_with_blocks(full_text, text_blocks)
            
            # BirleÅŸtir ve temizle
            combined_entities = self.merge_and_clean_entities(all_entities + regex_entities, confidence_threshold)
            
            self.logger.info(f"Toplam {len(combined_entities)} entity tespit edildi")
            return combined_entities
            
        except Exception as e:
            self.logger.error(f"Custom NER analiz hatasÄ±: {e}")
            return []
    
    def map_model_label_to_type(self, model_label: str) -> str:
        """Model etiketlerini uygulama tÃ¼rlerine eÅŸle"""
        # Modelinizin Ã§Ä±ktÄ± etiketlerine gÃ¶re bu mapping'i gÃ¼ncelleyin
        label_mapping = {
            'PERSON': 'ad_soyad',
            'PER': 'ad_soyad',
            'B-PERSON': 'ad_soyad',
            'I-PERSON': 'ad_soyad',
            'PHONE': 'telefon',
            'PHONE_NUMBER': 'telefon',
            'EMAIL': 'email',
            'ADDRESS': 'adres',
            'ORGANIZATION': 'sirket',
            'ORG': 'sirket',
            'MONEY': 'para',
            'DATE': 'tarih',
            'ID_NUMBER': 'tc_kimlik',
            'NATIONAL_ID': 'tc_kimlik'
        }
        return label_mapping.get(model_label.upper(), model_label.lower())
    
    def find_text_block_for_position(self, start_pos: int, end_pos: int, 
                                   text_blocks: List[Dict], full_text: str) -> Dict:
        """Verilen pozisyon iÃ§in text block bilgilerini bul"""
        current_pos = 0
        
        for block in text_blocks:
            block_text = block['text']
            block_start = current_pos
            block_end = current_pos + len(block_text)
            
            # Entity bu block iÃ§inde mi?
            if start_pos >= block_start and end_pos <= block_end + 1:
                # Block iÃ§indeki relatif pozisyonu hesapla
                relative_start = start_pos - block_start
                relative_end = end_pos - block_start
                
                return {
                    'page': block['page'],
                    'bbox': block['bbox'],
                    'font': block['font'],
                    'size': block['size'],
                    'flags': block['flags'],
                    'color': block['color'],
                    'relative_start': relative_start,
                    'relative_end': relative_end,
                    'block_text': block_text
                }
            
            current_pos = block_end + 1  # +1 for space/newline
        
        # BulunamadÄ± ise default deÄŸer
        return {
            'page': 0,
            'bbox': (0, 0, 100, 20),
            'font': 'Arial',
            'size': 12,
            'flags': 0,
            'color': 0,
            'relative_start': 0,
            'relative_end': 0,
            'block_text': ''
        }
    
    def perform_regex_detection_with_blocks(self, full_text: str, text_blocks: List[Dict]) -> List[Dict]:
        """Regex ile ek tespitler (pozisyon bilgisiyle)"""
        regex_entities = []
        
        # TC Kimlik pattern
        tc_pattern = r'\b[1-9][0-9]{9}[02468]\b'
        for match in re.finditer(tc_pattern, full_text):
            tc_no = match.group()
            if self.validate_turkish_id(tc_no):
                text_block_info = self.find_text_block_for_position(
                    match.start(), match.end(), text_blocks, full_text
                )
                
                regex_entities.append({
                    'entity': 'tc_kimlik',
                    'word': tc_no,
                    'start': match.start(),
                    'end': match.end(),
                    'score': 0.95,
                    'method': 'regex_validated',
                    'text_block_info': text_block_info
                })
        
        # Telefon pattern
        phone_pattern = r'\b0?5[0-9]{2}[\s\-]?[0-9]{3}[\s\-]?[0-9]{2}[\s\-]?[0-9]{2}\b'
        for match in re.finditer(phone_pattern, full_text):
            text_block_info = self.find_text_block_for_position(
                match.start(), match.end(), text_blocks, full_text
            )
            
            regex_entities.append({
                'entity': 'telefon',
                'word': match.group(),
                'start': match.start(),
                'end': match.end(),
                'score': 0.85,
                'method': 'regex',
                'text_block_info': text_block_info
            })
        
        # Email pattern
        email_pattern = r'\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Z|a-z]{2,}\b'
        for match in re.finditer(email_pattern, full_text):
            text_block_info = self.find_text_block_for_position(
                match.start(), match.end(), text_blocks, full_text
            )
            
            regex_entities.append({
                'entity': 'email',
                'word': match.group(),
                'start': match.start(),
                'end': match.end(),
                'score': 0.90,
                'method': 'regex',
                'text_block_info': text_block_info
            })
        
        return regex_entities
    
    def perform_font_preserving_replacement(self, input_path: str, entities: List[Dict], 
                                          output_path: str, text_blocks: List[Dict], progress) -> bool:
        """Font Ã¶zelliklerini koruyarak PDF deÄŸiÅŸtirme"""
        try:
            doc = fitz.open(input_path)
            total_replacements = 0
            
            progress(0.6, desc="Font bilgileri korunarak deÄŸiÅŸtiriliyor...")
            
            # Sayfa bazÄ±nda entity'leri grupla
            entities_by_page = {}
            for entity in entities:
                page_num = entity.get('text_block_info', {}).get('page', 0)
                if page_num not in entities_by_page:
                    entities_by_page[page_num] = []
                entities_by_page[page_num].append(entity)
            
            # Her sayfa iÃ§in iÅŸlem yap
            for page_num in range(len(doc)):
                if page_num not in entities_by_page:
                    continue
                
                page = doc.load_page(page_num)
                page_entities = entities_by_page[page_num]
                
                progress(0.6 + (page_num / len(doc)) * 0.2, 
                        desc=f"Sayfa {page_num + 1}/{len(doc)} iÅŸleniyor...")
                
                # Entity'leri pozisyona gÃ¶re sÄ±rala (tersten - sondan baÅŸa)
                page_entities.sort(key=lambda x: x.get('start', 0), reverse=True)
                
                for entity in page_entities:
                    success = self.replace_entity_with_font_preservation(page, entity)
                    if success:
                        total_replacements += 1
            
            doc.save(output_path)
            doc.close()
            
            self.logger.info(f"Font korumalÄ± deÄŸiÅŸtirme: {total_replacements} baÅŸarÄ±lÄ±")
            return total_replacements > 0
            
        except Exception as e:
            self.logger.error(f"Font korumalÄ± deÄŸiÅŸtirme hatasÄ±: {e}")
            return False
    
    def replace_entity_with_font_preservation(self, page, entity: Dict) -> bool:
        """Tek bir entity'yi font Ã¶zelliklerini koruyarak deÄŸiÅŸtir"""
        try:
            original_text = entity.get('word', '').strip()
            replacement_text = entity.get('replacement', original_text).strip()
            
            if not original_text or original_text == replacement_text:
                return False
            
            text_block_info = entity.get('text_block_info', {})
            bbox = text_block_info.get('bbox')
            
            if not bbox:
                self.logger.warning(f"Entity iÃ§in bbox bulunamadÄ±: {original_text}")
                return False
            
            # Orijinal metni bul ve pozisyonunu al
            text_instances = page.search_for(original_text)
            
            if not text_instances:
                self.logger.warning(f"Metin sayfada bulunamadÄ±: {original_text}")
                return False
            
            # En yakÄ±n bbox'Ä± bul
            target_rect = None
            min_distance = float('inf')
            
            for rect in text_instances:
                # Bbox'lar arasÄ±ndaki mesafeyi hesapla
                distance = abs(rect[0] - bbox[0]) + abs(rect[1] - bbox[1])
                if distance < min_distance:
                    min_distance = distance
                    target_rect = rect
            
            if target_rect is None:
                return False
            
            # Font Ã¶zelliklerini al (sadece boyut ve renk)
            font_size = text_block_info.get('size', 12)
            font_color = text_block_info.get('color', 0)
            
            # Orijinal metni sil (beyaz dikdÃ¶rtgen ile kapat)
            page.add_redact_annot(target_rect, fill=(1, 1, 1))
            page.apply_redactions()
            
            # Yeni metin iÃ§in pozisyon ayarla
            rect_width = target_rect[2] - target_rect[0]
            rect_height = target_rect[3] - target_rect[1]
            
            # Default font ile metin boyutunu hesapla
            default_font = 'helv'  # Helvetica (PDF standard font)
            text_width = fitz.get_text_length(replacement_text, fontname=default_font, fontsize=font_size)
            
            # Metin Ã§ok uzunsa font boyutunu kÃ¼Ã§Ã¼lt
            if text_width > rect_width * 1.1:  # %10 tolerans
                adjusted_font_size = font_size * (rect_width / text_width) * 0.9
                font_size = max(adjusted_font_size, 6)  # Minimum 6pt
            
            # RGB renk dÃ¶nÃ¼ÅŸtÃ¼rme
            if isinstance(font_color, int):
                # Integer color'Ä± RGB'ye Ã§evir
                rgb_color = (
                    ((font_color >> 16) & 255) / 255.0,
                    ((font_color >> 8) & 255) / 255.0,
                    (font_color & 255) / 255.0
                )
            else:
                rgb_color = (0, 0, 0)  # Siyah default
            
            # Metni ekle (default font ile)
            insert_point = (target_rect[0], target_rect[3] - 2)  # Biraz yukarÄ±dan
            
            page.insert_text(
                insert_point,
                replacement_text,
                fontsize=font_size,
                fontname=default_font,  # Default font kullan
                color=rgb_color,
                render_mode=0  # Normal text
            )
            
            self.logger.debug(f"Default font ile deÄŸiÅŸtirme: '{original_text}' -> '{replacement_text}' (Font: Helvetica, Boyut: {font_size})")
            return True
            
        except Exception as e:
            self.logger.error(f"Entity deÄŸiÅŸtirme hatasÄ±: {e}")
            return False
    
    def validate_turkish_id(self, tc_no: str) -> bool:
        """TC kimlik validasyonu"""
        if not tc_no or len(tc_no) != 11 or not tc_no.isdigit():
            return False
        if tc_no[0] == '0':
            return False
        digits = [int(d) for d in tc_no]
        odd_sum = sum(digits[i] for i in range(0, 9, 2))
        even_sum = sum(digits[i] for i in range(1, 8, 2))
        check_digit_10 = (odd_sum * 7 - even_sum) % 10
        if check_digit_10 != digits[9]:
            return False
        check_digit_11 = sum(digits[:10]) % 10
        if check_digit_11 != digits[10]:
            return False
        return True
    
    def merge_and_clean_entities(self, entities: List[Dict], confidence_threshold: float) -> List[Dict]:
        """Entity'leri birleÅŸtir ve temizle"""
        seen = set()
        cleaned = []
        for entity in entities:
            key = (entity.get('start', 0), entity.get('end', 0), entity.get('word', ''))
            if key not in seen:
                seen.add(key)
                cleaned.append(entity)
        filtered = [e for e in cleaned if e.get('score', 0) >= confidence_threshold]
        return sorted(filtered, key=lambda x: x.get('start', 0))
    
    # ------------ Faker yardÄ±mcÄ±larÄ± ------------
    def _seeded_faker(self, key: str) -> Faker:
        """AynÄ± 'key' iÃ§in deterministik Faker."""
        seeded = abs(hash(key)) % (10**9)
        f = Faker("tr_TR")
        f.seed_instance(seeded)
        return f

    def _fake_tc_kimlik(self, f: Faker) -> str:
        """GeÃ§erli checksum'lÄ± TR TCKN Ã¼ret."""
        while True:
            d = [0]*11
            d[0] = f.random_int(1, 9)
            for i in range(1, 9):
                d[i] = f.random_int(0, 9)
            odd_sum = sum(d[i] for i in range(0, 9, 2))
            even_sum = sum(d[i] for i in range(1, 8, 2))
            d[9] = (odd_sum * 7 - even_sum) % 10
            d[10] = (sum(d[:10]) % 10)
            tc = "".join(map(str, d))
            if self.validate_turkish_id(tc):
                return tc

    def _fake_phone_tr(self, f: Faker) -> str:
        """05xxxxxxxxx formatÄ±nda cep."""
        return "05" + "".join(str(f.random_int(0, 9)) for _ in range(9))

    def _fake_iban_tr(self, f: Faker) -> str:
        try:
            return f.iban(country_code="TR")
        except Exception:
            return "TR" + "".join(str(f.random_int(0, 9)) for _ in range(24))

    def _fake_company_tr(self, f: Faker) -> str:
        try:
            return f.company()
        except Exception:
            return "Ã–rnek A.Å."

    def _fake_address_tr(self, f: Faker) -> str:
        try:
            return f.address().replace("\n", ", ")
        except Exception:
            return "Ã–rnek Mah., Ã–rnek Cd., No:1, Ä°stanbul"

    def _fake_name_tr(self, f: Faker) -> str:
        try:
            return f.name()
        except Exception:
            return "Ali Demir"

    def _fake_email_from_name(self, f: Faker, name_full: str) -> str:
        import unicodedata, re
        def slugify(s: str) -> str:
            s = unicodedata.normalize("NFKD", s)
            s = "".join(c for c in s if not unicodedata.combining(c))
            s = s.lower()
            s = (s.replace("Ä±","i").replace("ÄŸ","g").replace("ÅŸ","s")
                   .replace("Ã§","c").replace("Ã¶","o").replace("Ã¼","u"))
            s = re.sub(r"[^a-z0-9]+", ".", s).strip(".")
            return s

        parts = (name_full or "").split()
        if len(parts) >= 2:
            user = f"{slugify(parts[0])}.{slugify(parts[-1])}"
        else:
            user = slugify(name_full or "kullanici")
        domain = f.random_element(["example.com","mail.com","ornek.com","kurum.com.tr"])
        return f"{user}@{domain}"
    
    def apply_replacement_strategy(self, entities: List[Dict], strategy: str, custom_replacements: str) -> List[Dict]:
        """DeÄŸiÅŸtirme stratejisini uygula (Faker destekli)."""
        default_replacements = {
            'ad_soyad': 'Ali Demir',
            'tc_kimlik': '11111111110',
            'telefon': '05009999999',
            'adres': 'Ã–rnek Mahallesi, Ä°stanbul',
            'para': '1000 TL',
            'tarih': '01.01.2000',
            'email': 'ornek@email.com',
            'sirket': 'Ã–rnek A.Å.',
            'iban': 'TR00 0000 0000 0000 0000 0000 00'
        }
        if custom_replacements and custom_replacements.strip():
            try:
                custom_dict = json.loads(custom_replacements)
                default_replacements.update(custom_dict)
            except json.JSONDecodeError as e:
                self.logger.warning(f"Custom replacements parse hatasÄ±: {e}")

        processed = []
        for entity in entities:
            e = entity.copy()
            etype = e.get('entity', '').strip()
            original = e.get('word', '')

            if strategy == "Maskeleme (*)":
                e['replacement'] = '*' * len(original)

            elif strategy == "Genel DeÄŸerler":
                generic_map = {
                    'ad_soyad': '[Ä°SÄ°M]',
                    'tc_kimlik': '[TC KÄ°MLÄ°K]',
                    'telefon': '[TELEFON]',
                    'adres': '[ADRES]',
                    'para': '[PARA]',
                    'tarih': '[TARÄ°H]',
                    'email': '[E-POSTA]',
                    'sirket': '[ÅÄ°RKET]',
                    'iban': '[IBAN]'
                }
                e['replacement'] = generic_map.get(etype, f'[{etype.upper()}]')

            elif strategy == "Sahte DeÄŸerler":
                # AynÄ± orijinal -> aynÄ± sahte deÄŸer (deterministik)
                f = self._seeded_faker(original if original else etype)

                # KullanÄ±cÄ±nÄ±n JSON ile verdiÄŸi tÃ¼r varsa Ã¶ncelik
                override = default_replacements.get(etype)
                candidate = None if override in (None, "") else override

                if candidate is None:
                    if etype == 'ad_soyad':
                        candidate = self._fake_name_tr(f)
                    elif etype == 'telefon':
                        candidate = self._fake_phone_tr(f)
                    elif etype == 'email':
                        base_name = original if original else self._fake_name_tr(f)
                        candidate = self._fake_email_from_name(f, base_name)
                    elif etype == 'adres':
                        candidate = self._fake_address_tr(f)
                    elif etype == 'sirket':
                        candidate = self._fake_company_tr(f)
                    elif etype == 'iban':
                        candidate = self._fake_iban_tr(f)
                    elif etype == 'tc_kimlik':
                        candidate = self._fake_tc_kimlik(f)
                    elif etype == 'para':
                        tl = f.pydecimal(left_digits=4, right_digits=2, positive=True)
                        candidate = f"{tl} TL"
                    elif etype == 'tarih':
                        dt = f.date_between(start_date="-10y", end_date="today")
                        candidate = dt.strftime("%d.%m.%Y")
                    else:
                        # TanÄ±msÄ±z tÃ¼r: uzunluÄŸu kabaca koruyan fallback
                        candidate = original if original else "â€”"

                e['replacement'] = candidate

            else:
                e['replacement'] = original

            processed.append(e)
        return processed
    
    def validate_pdf_changes(self, output_path: str, entities: List[Dict]) -> Dict:
        """PDF'teki deÄŸiÅŸiklikleri doÄŸrula"""
        try:
            doc = fitz.open(output_path)
            full_text = ""
            for page_num in range(len(doc)):
                page = doc.load_page(page_num)
                full_text += page.get_text()
            doc.close()
            
            validation_result = {
                'total_entities': len(entities),
                'successfully_replaced': 0,
                'still_present': [],
                'replacement_found': [],
                'partial_replacements': []
            }
            for entity in entities:
                original = entity.get('word', '').strip()
                replacement = entity.get('replacement', original).strip()
                if original in full_text:
                    validation_result['still_present'].append(original)
                else:
                    validation_result['successfully_replaced'] += 1
                if replacement in full_text and replacement != original:
                    validation_result['replacement_found'].append(replacement)
            return validation_result
        except Exception as e:
            self.logger.error(f"Validasyon hatasÄ±: {e}")
            return {'error': str(e)}
    
    def format_debug_info(self, validation_result: Dict, entities: List[Dict]) -> str:
        """Debug bilgilerini formatla"""
        if 'error' in validation_result:
            return f"âŒ Validasyon hatasÄ±: {validation_result['error']}"
        
        debug_info = f"""
## ğŸ” Debug Bilgileri

### DeÄŸiÅŸtirme SonuÃ§larÄ±:
- **Toplam Entity**: {validation_result['total_entities']}
- **BaÅŸarÄ±lÄ± DeÄŸiÅŸtirme**: {validation_result['successfully_replaced']}
- **Hala Mevcut**: {len(validation_result.get('still_present', []))}
- **Yeni DeÄŸerler Bulundu**: {len(validation_result.get('replacement_found', []))}

### Hala Mevcut Metinler:
{validation_result.get('still_present', [])[:5]}

### Bulunan Yeni DeÄŸerler:
{validation_result.get('replacement_found', [])[:5]}

### Model Bilgileri:
- **Model Yolu**: {self.model_path}
- **Model Durumu**: {'âœ… YÃ¼klendi' if self.ner_pipeline else 'âŒ YÃ¼klenemedi'}
        """.strip()
        return debug_info
    
    def create_detailed_statistics(self, entities: List[Dict], validation_result: Dict) -> pd.DataFrame:
        """DetaylÄ± istatistik tablosu"""
        if not entities:
            return pd.DataFrame(columns=['Veri TÃ¼rÃ¼', 'Tespit', 'DeÄŸiÅŸtirildi', 'BaÅŸarÄ± OranÄ±', 'Ã–rnek'])
        
        stats = {}
        for entity in entities:
            etype = entity['entity']
            if etype not in stats:
                stats[etype] = {'detected': 0, 'examples': [], 'originals': [], 'replacements': []}
            stats[etype]['detected'] += 1
            stats[etype]['originals'].append(entity.get('word', ''))
            stats[etype]['replacements'].append(entity.get('replacement', ''))
            if len(stats[etype]['examples']) < 2:
                stats[etype]['examples'].append(entity.get('word', ''))
        
        rows = []
        names = {
            'ad_soyad': 'ğŸ‘¤ Ad Soyad',
            'tc_kimlik': 'ğŸ†” TC Kimlik', 
            'telefon': 'ğŸ“± Telefon',
            'adres': 'ğŸ“ Adres',
            'para': 'ğŸ’° Para',
            'tarih': 'ğŸ“… Tarih',
            'email': 'ğŸ“§ E-posta',
            'sirket': 'ğŸ¢ Åirket'
        }
        for etype, data in stats.items():
            successful = 0
            for original in data['originals']:
                if original not in validation_result.get('still_present', []):
                    successful += 1
            success_rate = (successful / data['detected'] * 100) if data['detected'] > 0 else 0
            rows.append({
                'Veri TÃ¼rÃ¼': names.get(etype, etype.title()),
                'Tespit': data['detected'],
                'DeÄŸiÅŸtirildi': successful,
                'BaÅŸarÄ± OranÄ±': f"{success_rate:.1f}%",
                'Ã–rnek': ', '.join(data['examples'][:2])
            })
        return pd.DataFrame(rows)
    
    def generate_detailed_summary(self, entities: List[Dict], validation_result: Dict, filename: str) -> str:
        """DetaylÄ± Ã¶zet oluÅŸtur"""
        if not entities:
            return "âŒ HiÃ§bir kiÅŸisel bilgi tespit edilmedi."
        
        total_entities = len(entities)
        successful = validation_result.get('successfully_replaced', 0)
        still_present = len(validation_result.get('still_present', []))
        success_rate = (successful / total_entities * 100) if total_entities > 0 else 0
        
        if success_rate >= 90:
            status_emoji = "ğŸŸ¢"; status_text = "MÃ¼kemmel"
        elif success_rate >= 70:
            status_emoji = "ğŸŸ¡"; status_text = "Ä°yi"
        else:
            status_emoji = "ğŸ”´"; status_text = "Dikkat Gerekli"
        
        summary = f"""
## ğŸ“Š DetaylÄ± Ä°ÅŸlem Raporu

**Dosya:** {filename}  
**Tarih:** {datetime.now().strftime('%d.%m.%Y %H:%M')}

### {status_emoji} Genel BaÅŸarÄ±: {status_text} ({success_rate:.1f}%)

### ğŸ¯ DeÄŸiÅŸtirme SonuÃ§larÄ±
- **Toplam Tespit:** {total_entities} adet
- **BaÅŸarÄ±lÄ± DeÄŸiÅŸtirme:** {successful} adet  
- **Hala Mevcut:** {still_present} adet

### ğŸ“ˆ Performans Analizi
""".strip()
        if success_rate >= 90:
            summary += "\n\nâœ… **Harika!** Neredeyse tÃ¼m kiÅŸisel bilgiler baÅŸarÄ±yla deÄŸiÅŸtirildi."
        elif success_rate >= 70:
            summary += "\n\nâš ï¸ **Ä°yi performans** ancak bazÄ± bilgiler deÄŸiÅŸtirilemedi. Manuel kontrol Ã¶nerilir."
        else:
            summary += "\n\nğŸš¨ **Dikkat!** Ã‡oÄŸu bilgi deÄŸiÅŸtirilemedi. FarklÄ± yÃ¶ntem denemeyi dÃ¼ÅŸÃ¼nÃ¼n."
        
        if still_present > 0:
            still_present_list = validation_result.get('still_present', [])[:3]
            summary += "\n\n### ğŸ” DeÄŸiÅŸtirilemeyen Ã–rnekler:\n"
            for item in still_present_list:
                summary += f"- `{item}`\n"
        return summary
    
    def log_processing_with_validation(self, filename: str, entities: List[Dict], validation_result: Dict):
        log_entry = {
            'timestamp': datetime.now().isoformat(),
            'filename': filename,
            'total_entities': len(entities),
            'successful_replacements': validation_result.get('successfully_replaced', 0),
            'still_present_count': len(validation_result.get('still_present', [])),
            'success_rate': (validation_result.get('successfully_replaced', 0) / len(entities) * 100) if entities else 0,
            'entities': entities,
            'validation_result': validation_result
        }
        log_file = f"logs/detailed_session_{datetime.now().strftime('%Y%m%d')}.json"
        logs = []
        if os.path.exists(log_file):
            try:
                with open(log_file, 'r', encoding='utf-8') as f:
                    logs = json.load(f)
            except Exception:
                logs = []
        logs.append(log_entry)
        with open(log_file, 'w', encoding='utf-8') as f:
            # --- BURADA default=self._json_safe EKLENDÄ° ---
            json.dump(logs, f, ensure_ascii=False, indent=2, default=self._json_safe)

    
    def get_processing_history(self) -> pd.DataFrame:
        """Ä°ÅŸlem geÃ§miÅŸini al"""
        try:
            log_files = []
            for i in range(7):
                date_str = (datetime.now() - pd.Timedelta(days=i)).strftime('%Y%m%d')
                log_file = f"logs/detailed_session_{date_str}.json"
                if os.path.exists(log_file):
                    log_files.append(log_file)
            all_logs = []
            for log_file in log_files:
                with open(log_file, 'r', encoding='utf-8') as f:
                    logs = json.load(f)
                    all_logs.extend(logs)
            if not all_logs:
                return pd.DataFrame(columns=['Tarih', 'Dosya', 'Toplam Tespit', 'BaÅŸarÄ±lÄ±', 'BaÅŸarÄ± OranÄ±'])
            rows = []
            for log in all_logs[-50:]:
                timestamp = datetime.fromisoformat(log['timestamp'])
                rows.append({
                    'Tarih': timestamp.strftime('%d.%m.%Y %H:%M'),
                    'Dosya': log['filename'],
                    'Toplam Tespit': log['total_entities'],
                    'BaÅŸarÄ±lÄ±': log.get('successful_replacements', 0),
                    'BaÅŸarÄ± OranÄ±': f"{log.get('success_rate', 0):.1f}%"
                })
            return pd.DataFrame(rows)
        except Exception:
            return pd.DataFrame(columns=['Tarih', 'Dosya', 'Toplam Tespit', 'BaÅŸarÄ±lÄ±', 'BaÅŸarÄ± OranÄ±'])
    
    # -----------------------------
    # Gradio UI
    # -----------------------------
    def create_enhanced_interface(self):
        """GeliÅŸmiÅŸ Gradio arayÃ¼zÃ¼"""
        css = """
        .gradio-container { font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif; }
        .debug-info { background-color: #f8f9fa; padding: 10px; border-radius: 5px; font-family: monospace; font-size: 12px; }
        .model-status { padding: 10px; border-radius: 5px; margin: 10px 0; }
        .model-loaded { background-color: #d4edda; border: 1px solid #c3e6cb; color: #155724; }
        .model-error { background-color: #f8d7da; border: 1px solid #f5c6cb; color: #721c24; }
        """
        
        with gr.Blocks(css=css, title="PDF KiÅŸisel Bilgi AnonimleÅŸtirici - Custom NER", theme=gr.themes.Soft()) as interface:
            # Model durumu gÃ¶ster
            model_status = "âœ… Custom NER Model YÃ¼klendi" if self.ner_pipeline else "âŒ Model YÃ¼klenemedi"
            model_class = "model-loaded" if self.ner_pipeline else "model-error"
            
            gr.Markdown(f"""
            # ğŸ” PDF KiÅŸisel Bilgi AnonimleÅŸtirici â€” Custom NER
            YÃ¼klediÄŸiniz PDF'teki kiÅŸisel bilgileri **Ã¶zel modelinizle tespit eder** ve **font Ã¶zelliklerini koruyarak deÄŸiÅŸtirir**.
            
            <div class="model-status {model_class}">
            ğŸ¤– **Model Durumu**: {model_status}<br>
            ğŸ“ **Model Yolu**: {self.model_path}
            </div>
            """)
            
            with gr.Tabs():
                # ------------------ Ana Ä°ÅŸlem Sekmesi ------------------
                with gr.TabItem("ğŸ“„ PDF Ä°ÅŸleme", elem_id="main-tab"):
                    with gr.Row():
                        with gr.Column(scale=1):
                            pdf_input = gr.File(
                                label="ğŸ“ PDF DosyasÄ± YÃ¼kleyin",
                                file_types=[".pdf"],
                                type="filepath"
                            )
                            
                            gr.Markdown("### âš™ï¸ Ä°ÅŸlem AyarlarÄ±")
                            
                            confidence_threshold = gr.Slider(
                                minimum=0.1, maximum=1.0, value=0.7, step=0.1,
                                label="ğŸ¯ GÃ¼ven EÅŸiÄŸi"
                            )
                            
                            replacement_strategy = gr.Radio(
                                choices=["Maskeleme (*)", "Sahte DeÄŸerler", "Genel DeÄŸerler"],
                                value="Sahte DeÄŸerler",
                                label="ğŸ” DeÄŸiÅŸtirme Stratejisi"
                            )
                            
                            with gr.Accordion("ğŸ§© Ã–zel DeÄŸer HaritasÄ± (JSON)", open=False):
                                gr.Markdown("Ã–rnek:")
                                example_json = {
                                    "ad_soyad": "Mehmet YÄ±lmaz",
                                    "telefon": "05551234567",
                                    "email": "anonim@example.com",
                                    "adres": "Ankara, TÃ¼rkiye"
                                }
                                gr.Code(value=json.dumps(example_json, ensure_ascii=False, indent=2), language="json")
                                custom_replacements = gr.Textbox(
                                    label="Ã–zel DeÄŸerler (JSON)",
                                    placeholder='{"ad_soyad": "Mehmet YÄ±lmaz", "telefon": "0555..."}',
                                    lines=5
                                )
                            
                            enable_logging = gr.Checkbox(value=True, label="ğŸ§¾ Log kaydÄ± tut")
                            enable_debug = gr.Checkbox(value=False, label="ğŸ Debug bilgilerini gÃ¶ster")
                            
                            process_btn = gr.Button(
                                "ğŸš€ Ä°ÅŸlemi BaÅŸlat", 
                                variant="primary",
                                interactive=bool(self.ner_pipeline)
                            )
                            
                            if not self.ner_pipeline:
                                gr.Markdown("âš ï¸ **UyarÄ±**: Model yÃ¼klenemediÄŸi iÃ§in iÅŸlem baÅŸlatÄ±lamaz.")
                        
                        with gr.Column(scale=1):
                            output_pdf = gr.File(label="ğŸ“¤ AnonimleÅŸtirilmiÅŸ PDF", file_count="single")
                            status_text = gr.Markdown("â³ HenÃ¼z iÅŸlem yapÄ±lmadÄ±.")
                            summary_md = gr.Markdown("")
                            stats_df = gr.Dataframe(headers=["Veri TÃ¼rÃ¼", "Tespit", "DeÄŸiÅŸtirildi", "BaÅŸarÄ± OranÄ±", "Ã–rnek"], interactive=False)
                            debug_out = gr.Textbox(label="Debug", lines=15, visible=False)
                    
                        # Buton-click baÄŸlama
                        def _wrap_process(pdf, thr, strat, custom_json, log_on, dbg_on, progress=gr.Progress()):
                            out_path, status, summary, df, dbg = self.process_pdf_with_real_replacement(
                                pdf, thr, strat, custom_json or "", log_on, dbg_on, "font_preserving", progress
                            )
                            # Debug gÃ¶rÃ¼nÃ¼rlÃ¼ÄŸÃ¼
                            return (
                                out_path, 
                                status, 
                                summary, 
                                df, 
                                gr.update(value=dbg, visible=bool(dbg_on))
                            )
                        
                        process_btn.click(
                            _wrap_process,
                            inputs=[pdf_input, confidence_threshold, replacement_strategy, custom_replacements, enable_logging, enable_debug],
                            outputs=[output_pdf, status_text, summary_md, stats_df, debug_out],
                            api_name="process_pdf"
                        )
                    
                    # ------------------ Model Test ------------------
                    with gr.TabItem("ğŸ§ª Model Test"):
                        gr.Markdown("### Custom NER Model Testi")
                        
                        test_text = gr.Textbox(
                            label="Test Metni",
                            placeholder="Ã–rnek: Ahmet YÄ±lmaz 05551234567 numaralÄ± telefonu kullanÄ±yor.",
                            lines=5
                        )
                        test_confidence = gr.Slider(
                            minimum=0.1, maximum=1.0, value=0.5, step=0.1,
                            label="Test GÃ¼ven EÅŸiÄŸi"
                        )
                        test_btn = gr.Button("ğŸ” Test Et", variant="secondary")
                        test_results = gr.JSON(label="Test SonuÃ§larÄ±")
                        
                        def test_model(text, conf_threshold):
                            if not self.ner_pipeline or not text.strip():
                                return {"error": "Model yÃ¼klÃ¼ deÄŸil veya metin boÅŸ"}
                            
                            try:
                                results = self.ner_pipeline(text)
                                filtered_results = [
                                    {
                                        'entity': self.map_model_label_to_type(r['entity_group']),
                                        'word': r['word'],
                                        'score': round(r['score'], 3),
                                        'start': r['start'],
                                        'end': r['end'],
                                        'original_label': r['entity_group']
                                    }
                                    for r in results if r['score'] >= conf_threshold
                                ]
                                return {
                                    "entities_found": len(filtered_results),
                                    "results": filtered_results
                                }
                            except Exception as e:
                                return {"error": str(e)}
                        
                        test_btn.click(
                            test_model,
                            inputs=[test_text, test_confidence],
                            outputs=test_results
                        )
                    
                    # ------------------ GeÃ§miÅŸ ------------------
                    with gr.TabItem("ğŸ—‚ï¸ GeÃ§miÅŸ"):
                        gr.Markdown("Son iÅŸlemlerin Ã¶zeti (loglardan derlenir).")
                        history_df = gr.Dataframe(interactive=False)
                        refresh_btn = gr.Button("ğŸ”„ Yenile")
                        
                        def _load_history():
                            return self.get_processing_history()
                        
                        refresh_btn.click(_load_history, inputs=None, outputs=history_df)
                        interface.load(_load_history, inputs=None, outputs=history_df)
                    
                    # ------------------ YardÄ±m ------------------
                    with gr.TabItem("â“ YardÄ±m"):
                        gr.Markdown(f"""
    ### ğŸ¤– Custom NER Model Bilgileri
    - **Model Yolu**: `{self.model_path}`
    - **Model Durumu**: {'âœ… YÃ¼klendi ve hazÄ±r' if self.ner_pipeline else 'âŒ YÃ¼klenemedi'}
    - **Ä°ÅŸlem YÃ¶ntemi**: Font Ã¶zelliklerini koruyarak deÄŸiÅŸtirme

            ### ğŸ”§ GeliÅŸmiÅŸ Ã–zellikler
    - **Default Font**: TÃ¼m deÄŸiÅŸtirmeler Helvetica font ile yapÄ±lÄ±r
    - **Boyut Koruma**: Orijinal font boyutu korunur (uzun metinler iÃ§in otomatik kÃ¼Ã§Ã¼ltme)
    - **Renk Koruma**: Orijinal metin rengi korunur
    - **Pozisyon Hassasiyeti**: Metinler tam pozisyonlarÄ±nda deÄŸiÅŸtirilir, Ã¼st Ã¼ste binme Ã¶nlenir
    - **AkÄ±llÄ± BoyutlandÄ±rma**: Uzun metinler iÃ§in font boyutu otomatik ayarlanÄ±r
    - **Ã‡oklu YÃ¶ntem**: Model + Regex kombinasyonu iÃ§in maksimum tespit

    ### ğŸ“‹ Gerekli Paketler
    ```bash
    pip install gradio pandas pymupdf transformers torch faker
    ```

    ### âš™ï¸ Model Etiket EÅŸleÅŸtirme
    Modelinizin Ã§Ä±kardÄ±ÄŸÄ± etiketler otomatik olarak uygulama tÃ¼rlerine eÅŸleÅŸtirilir:
    - `PERSON/PER` â†’ Ad Soyad
    - `PHONE/PHONE_NUMBER` â†’ Telefon  
    - `EMAIL` â†’ E-posta
    - `ORGANIZATION/ORG` â†’ Åirket
    - `ID_NUMBER/NATIONAL_ID` â†’ TC Kimlik

            ### ğŸš¨ Ã–nemli Notlar
    1. **YazÄ± Ã‡akÄ±ÅŸmasÄ±**: Yeni metinler orijinal pozisyonlarda, default Helvetica font ile yerleÅŸtirilir
    2. **Font Boyutu**: Orijinal boyut korunur, uzun metinler iÃ§in otomatik kÃ¼Ã§Ã¼ltÃ¼lÃ¼r
    3. **Renk Koruma**: Orijinal metin rengi korunur
    4. **SÄ±ralama**: DeÄŸiÅŸtirmeler sondan baÅŸa yapÄ±lÄ±r (pozisyon kaymasÄ± Ã¶nlenir)
                        """)

                return interface

if __name__ == "__main__":
    app = EnhancedAnonymizationApp()
    demo = app.create_enhanced_interface()
    demo.launch(server_name="0.0.0.0", server_port=7860, show_error=True)