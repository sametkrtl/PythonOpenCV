

import gradio as gr
import os
import time
import json
import pandas as pd
from datetime import datetime
from pathlib import Path
import tempfile
import shutil
from typing import List, Dict, Tuple, Optional
import logging
import random
import torch
from transformers import AutoTokenizer, AutoModelForTokenClassification, pipeline
import fitz  # PyMuPDF
import re
import numpy as np
import unicodedata
# Import custom data lists
from datalar import (
    iban_samples, email_samples, adres_len_samples, ad_soyad_len_samples,
    sirket_len_samples, tarih_samples, telefon_samples, adres_samples,
    para_samples, ad_soyad_samples, sirket_samples
)


# ----------------------------------------------------
#  EnhancedAnonymizationApp  (Custom Data Lists + TutarlÄ± DeÄŸiÅŸtirme + Karakter SayÄ±sÄ± Koruma)
# ----------------------------------------------------
class EnhancedAnonymizationApp:
    def __init__(self):
        # Logger ayarlarÄ±
        logging.basicConfig(level=logging.INFO)
        self.logger = logging.getLogger(__name__)

        # Model yolunu belirtin
        self.model_path = r"C:\Users\stj.skartal\Desktop\python\samet\ner_model_final"

        # NER pipeline'Ä±nÄ± yÃ¼kle
        self.ner_pipeline = self.load_custom_ner_model()
        self.strict_lists_only = True

        # TutarlÄ± sahte Ã¼retim iÃ§in sabit seed
        self.global_seed = 123456
        random.seed(self.global_seed)

        # AynÄ± kelime -> aynÄ± deÄŸiÅŸtirme mapping'i
        self.replacement_cache = {}

        # Custom data lists - organize by length for exact matching
        self.organized_data = self._organize_data_by_length()

        # Dizinleri oluÅŸtur
        for dir_name in ["uploads", "outputs", "logs", "temp"]:
            os.makedirs(dir_name, exist_ok=True)

        self.processing_stats = []
    def _normalize_for_pdf_search(self, s: str) -> str:
        s = unicodedata.normalize("NFKC", s)
        s = s.replace("\u00A0", " ").replace("\u2009", " ").replace("\u202F", " ")
        s = re.sub(r"[ \t]+", " ", s).strip()
        return s

    def _candidate_queries(self, orig: str) -> List[str]:
        base = self._normalize_for_pdf_search(orig or "")
        cand = {base}

        # boÅŸluk / noktalama normalizasyonlarÄ±
        cand.add(re.sub(r"\s*([./-])\s*", r"\1", base))  # 05. 06. 2023 -> 05.06.2023
        cand.add(re.sub(r"\s+", " ", base))              # Ã§oklu boÅŸluk -> tek
        if len(base) <= 64:
            cand.add(base.replace(" ", ""))              # tÃ¼m boÅŸluklarÄ± kaldÄ±r (kÄ±sa metinlerde)

        # CASE varyantlarÄ± (case-insensitive davranÄ±ÅŸa yaklaÅŸmak iÃ§in)
        cand.add(base.upper())
        cand.add(base.lower())
        cand.add(base.title())

        return [c for c in cand if c]


    
    def _organize_data_by_length(self):
        """Veri listelerini karakter uzunluÄŸuna gÃ¶re organize et"""
        organized = {
            'ad_soyad': {},
            'telefon': {},
            'email': {},
            'adres': {},
            'sirket': {},
            'iban': {},
            'tarih': {},
            'para': {}
        }

        # Ad Soyad - hem genel liste hem de uzunluk bazlÄ±
        for item in ad_soyad_samples:
            length = len(item)
            if length not in organized['ad_soyad']:
                organized['ad_soyad'][length] = []
            organized['ad_soyad'][length].append(item)

        # Uzunluk bazlÄ± ad soyad verilerini ekle
        for length_data in ad_soyad_len_samples:
            length = length_data['length']
            if length not in organized['ad_soyad']:
                organized['ad_soyad'][length] = []
            organized['ad_soyad'][length].extend(length_data['samples'])

        # Telefon
        for item in telefon_samples:
            length = len(item)
            if length not in organized['telefon']:
                organized['telefon'][length] = []
            organized['telefon'][length].append(item)

        # Email
        for item in email_samples:
            length = len(item)
            if length not in organized['email']:
                organized['email'][length] = []
            organized['email'][length].append(item)

        # Adres - hem genel liste hem de uzunluk bazlÄ±
        for item in adres_samples:
            length = len(item)
            if length not in organized['adres']:
                organized['adres'][length] = []
            organized['adres'][length].append(item)

        for length_data in adres_len_samples:
            length = length_data['length']
            if length not in organized['adres']:
                organized['adres'][length] = []
            organized['adres'][length].extend(length_data['samples'])

        # Åžirket - hem genel liste hem de uzunluk bazlÄ±
        for item in sirket_samples:
            length = len(item)
            if length not in organized['sirket']:
                organized['sirket'][length] = []
            organized['sirket'][length].append(item)

        for length_data in sirket_len_samples:
            length = length_data['length']
            if length not in organized['sirket']:
                organized['sirket'][length] = []
            organized['sirket'][length].extend(length_data['samples'])

        # IBAN
        for item in iban_samples:
            length = len(item)
            if length not in organized['iban']:
                organized['iban'][length] = []
            organized['iban'][length].append(item)

        # Tarih
        for item in tarih_samples:
            length = len(item)
            if length not in organized['tarih']:
                organized['tarih'][length] = []
            organized['tarih'][length].append(item)

        # Para
        for item in para_samples:
            length = len(item)
            if length not in organized['para']:
                organized['para'][length] = []
            organized['para'][length].append(item)

        return organized
    
    def _get_deterministic_random(self, seed_text: str) -> random.Random:
        """Deterministik random generator"""
        seeded_value = abs(hash(seed_text)) % (10 ** 9)
        rng = random.Random()
        rng.seed(seeded_value)
        return rng

    def generate_text_with_exact_length(self, target_length: int, entity_type: str, seed_text: str) -> str:
        """
        Sadece Custom Lists'ten, TAM uzunluk eÅŸleÅŸmesi ile deÄŸer dÃ¶ndÃ¼r.
        HiÃ§bir koÅŸulda rastgele Ã¼retim / uzatma / kÄ±saltma yapmaz.
        Uygun Ã¶rnek yoksa KeyError fÄ±rlatÄ±r.
        """
        rng = self._get_deterministic_random(seed_text)

        # Liste ve uzunluk kontrolÃ¼
        lengths_dict = self.organized_data.get(entity_type, {})
        samples = lengths_dict.get(target_length, [])

        if samples:
            return rng.choice(samples)

        # SÄ±kÄ± modda: asla fallback yapma
        raise KeyError(f"No sample in lists for entity_type='{entity_type}' with length={target_length}")
    
    def _search_quads_near(self, page, query: str, ref_bbox, max_hits=64):
        try:
            tp = page.get_textpage()

            # Case-ignore flag'i varsa topla
            flags = 0
            for name in ("TEXT_SEARCH_IGNORE_CASE", "TEXT_IGNORECASE"):
                if hasattr(fitz, name):
                    flags |= getattr(fitz, name)

            # bazÄ± sÃ¼rÃ¼mlerde flags argÃ¼manÄ± yok -> try / except
            try:
                hits = tp.search(query, hit_max=max_hits, quads=True, flags=flags)
            except TypeError:
                hits = tp.search(query, hit_max=max_hits, quads=True)

            if not hits:
                return None

            rx0, ry0, rx1, ry1 = ref_bbox
            best, best_dist = None, float("inf")
            for h in hits:
                q = h[0] if isinstance(h, (list, tuple)) else h
                rect = fitz.Rect(q.rect) if hasattr(q, "rect") else fitz.Rect(q)
                dist = abs(rect.x0 - rx0) + abs(rect.y0 - ry0)
                if dist < best_dist:
                    best, best_dist = h, dist
            return best
        except Exception:
            return None

    def _rect_from_block_slice_chars(self, page, text_block_info) -> Optional[fitz.Rect]:
        """
        AynÄ± span'daki substring'in char bbox'larÄ±nÄ± birleÅŸtirerek bir Rect dÃ¶ndÃ¼rÃ¼r.
        'rawdict' iÃ§inde ilgili span'Ä±, text + bbox yakÄ±nlÄ±ÄŸÄ± ile bulur.
        """
        try:
            block_text = text_block_info.get('block_text', '')
            rel_s = int(text_block_info.get('relative_start', 0))
            rel_e = int(text_block_info.get('relative_end', 0))
            if not block_text or rel_e <= rel_s:
                return None

            target_text_norm = self._normalize_for_pdf_search(block_text)
            bx0, by0, bx1, by1 = text_block_info.get('bbox', (0,0,0,0))

            raw = page.get_text("rawdict")
            for b in raw.get("blocks", []):
                for l in b.get("lines", []):
                    for s in l.get("spans", []):
                        span_text = (s.get("text") or "")
                        span_bbox = s.get("bbox", None)
                        if not span_bbox:
                            continue

                        # hem metni hem bbox'Ä± yakÄ±n olmalÄ±
                        span_text_norm = self._normalize_for_pdf_search(span_text)
                        sx0, sy0, sx1, sy1 = span_bbox
                        bbox_dist = abs(sx0 - bx0) + abs(sy0 - by0)  # kaba yakÄ±nlÄ±k Ã¶lÃ§Ã¼sÃ¼

                        if span_text_norm == target_text_norm and bbox_dist < 10.0:
                            chars = s.get("chars")
                            if not chars:
                                # chars yoksa yaklaÅŸÄ±k olarak geniÅŸlik oranÄ±ndan kes
                                # (Ã§ok nadiren olur)
                                total_w = sx1 - sx0
                                if total_w <= 0:
                                    return fitz.Rect(span_bbox)
                                frac_s = rel_s / max(len(span_text), 1)
                                frac_e = rel_e / max(len(span_text), 1)
                                x0 = sx0 + total_w * frac_s
                                x1 = sx0 + total_w * frac_e
                                return fitz.Rect(min(x0,x1), sy0, max(x0,x1), sy1)

                            # char'larÄ±n bbox'larÄ±nÄ± birleÅŸtir
                            xs, ys = [], []
                            N = len(chars)
                            a = max(0, min(rel_s, N-1))
                            bnd = max(a+1, min(rel_e, N))
                            for ch in chars[a:bnd]:
                                cb = ch.get("bbox")
                                if not cb:
                                    continue
                                cx0, cy0, cx1, cy1 = cb
                                xs.extend([cx0, cx1]); ys.extend([cy0, cy1])

                            if xs and ys:
                                return fitz.Rect(min(xs), min(ys), max(xs), max(ys))
                            return fitz.Rect(span_bbox)
            return None
        except Exception:
            return None

    def _rects_from_hit(self, hit) -> List[fitz.Rect]:
            rects = []
            def to_rect(obj):
                if isinstance(obj, fitz.Rect):
                    return obj
                if hasattr(obj, "rect"):
                    try: return fitz.Rect(obj.rect)
                    except Exception: pass
                if isinstance(obj, (list, tuple)) and len(obj) == 4 and all(hasattr(p, "x") and hasattr(p, "y") for p in obj):
                    xs = [p.x for p in obj]; ys = [p.y for p in obj]
                    return fitz.Rect(min(xs), min(ys), max(xs), max(ys))
                return None
            def walk(o):
                r = to_rect(o)
                if r is not None:
                    rects.append(r); return
                if isinstance(o, (list, tuple)):
                    for it in o: walk(it)
            walk(hit)
            return [fitz.Rect(r) for r in rects if r is not None]



    def _generate_valid_tc_with_length(self, target_length: int, rng: random.Random) -> str:
        """GeÃ§erli TC kimlik numarasÄ± Ã¼ret"""
        if target_length != 11:
            # 11 karakter deÄŸilse, sayÄ± + harf kombinasyonu yap
            return ''.join(rng.choices('0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZ', k=target_length))

        # 11 karakter iÃ§in geÃ§erli TC Ã¼ret
        for _ in range(100):  # 100 deneme
            d = [0] * 11
            d[0] = rng.randint(1, 9)
            for i in range(1, 9):
                d[i] = rng.randint(0, 9)

            # Checksum hesapla
            odd_sum = sum(d[i] for i in range(0, 9, 2))
            even_sum = sum(d[i] for i in range(1, 8, 2))
            d[9] = (odd_sum * 7 - even_sum) % 10
            d[10] = sum(d[:10]) % 10

            tc = "".join(map(str, d))
            if self.validate_turkish_id(tc):
                return tc

        # Bulunamazsa basit bir deÄŸer dÃ¶ndÃ¼r
        return '12345678901'

    def _generate_generic_value(self, target_length: int, entity_type: str, rng: random.Random) -> str:
        """Generic deÄŸer Ã¼ret"""
        if entity_type == 'ad_soyad':
            chars = 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz '
        elif entity_type in ['telefon', 'tc_kimlik']:
            chars = '0123456789'
        elif entity_type == 'email':
            if target_length < 5:
                return 'a@b.c'[:target_length]
            base = 'user@example.com'
            if len(base) == target_length:
                return base
            elif len(base) < target_length:
                extra = 'x' * (target_length - len(base))
                return f"user{extra}@example.com"
            else:
                return base[:target_length]
        elif entity_type == 'para':
            if target_length <= 3:
                return 'â‚º' + '1' * (target_length - 1)
            else:
                numbers = ''.join(str(rng.randint(0, 9)) for _ in range(target_length - 3))
                return f"{numbers} TL"
        elif entity_type == 'tarih':
            # Tarih formatÄ± dene
            if target_length == 8:
                return f"{rng.randint(1, 28):02d}.{rng.randint(1, 12):02d}.{rng.randint(20, 99):02d}"
            elif target_length == 10:
                return f"{rng.randint(1, 28):02d}.{rng.randint(1, 12):02d}.{rng.randint(1900, 2099)}"
            else:
                chars = '0123456789.'
        elif entity_type == 'iban':
            return 'TR' + ''.join(str(rng.randint(0, 9)) for _ in range(target_length - 2))
        else:
            chars = 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789'

        if 'chars' in locals():
            return ''.join(rng.choices(chars, k=target_length))
        else:
            return 'X' * target_length

    def load_custom_ner_model(self):
        """Ã–zel NER modelini yÃ¼kle"""
        try:
            if not os.path.exists(self.model_path):
                self.logger.error(f"Model bulunamadÄ±: {self.model_path}")
                return None

            self.logger.info(f"Model yÃ¼kleniyor: {self.model_path}")

            # Tokenizer ve model yÃ¼kle
            tokenizer = AutoTokenizer.from_pretrained(self.model_path)
            model = AutoModelForTokenClassification.from_pretrained(self.model_path)

            # Pipeline oluÅŸtur
            ner_pipeline = pipeline(
                "ner",
                model=model,
                tokenizer=tokenizer,
                aggregation_strategy="simple",
                device=0 if torch.cuda.is_available() else -1
            )

            self.logger.info("Model baÅŸarÄ±yla yÃ¼klendi!")
            return ner_pipeline

        except Exception as e:
            self.logger.error(f"Model yÃ¼kleme hatasÄ±: {e}")
            return None

    def extract_text_with_positions(self, pdf_path: str) -> List[Dict]:
        try:
            doc = fitz.open(pdf_path)
            text_blocks = []
            for page_num in range(len(doc)):
                page = doc.load_page(page_num)
                blocks = page.get_text("dict")
                for block in blocks.get("blocks", []):
                    if "lines" in block:
                        for line in block["lines"]:
                            for span in line.get("spans", []):
                                text = (span.get("text") or "").strip()
                                if text:
                                    # --- TÄ°P DÃ–NÃœÅžÃœMLERÄ°: float32 â†’ float, vs. ---
                                    bbox_raw = span.get("bbox", (0, 0, 0, 0))
                                    # fitz Rect ya da tuple olabilir
                                    if hasattr(bbox_raw, "__iter__"):
                                        bbox = tuple(float(x) for x in bbox_raw)
                                    else:
                                        # Rect ise
                                        try:
                                            bbox = (float(bbox_raw.x0), float(bbox_raw.y0),
                                                    float(bbox_raw.x1), float(bbox_raw.y1))
                                        except Exception:
                                            bbox = (0.0, 0.0, 0.0, 0.0)

                                    size = float(span.get("size", 12))
                                    flags = int(span.get("flags", 0))
                                    color = span.get("color", 0)
                                    # color bazen float olabilir; int'e gÃ¼venli dÃ¶ndÃ¼r
                                    try:
                                        color = int(color)
                                    except Exception:
                                        color = 0

                                    text_blocks.append({
                                        'page': int(page_num),
                                        'text': text,
                                        'bbox': bbox,  # artÄ±k saf Python float tuple
                                        'font': str(span.get("font") or "Unknown"),
                                        'size': size,
                                        'flags': flags,
                                        'color': color,
                                        'start_char': 0,
                                        'end_char': 0
                                    })
            doc.close()

            # global pozisyonlar
            char_position = 0
            for block in text_blocks:
                block['start_char'] = int(char_position)
                char_position += len(block['text']) + 1
                block['end_char'] = int(char_position - 1)

            return text_blocks
        except Exception as e:
            self.logger.error(f"Metin Ã§Ä±karma hatasÄ±: {e}")
            return []

    # --- EKLE: JSON gÃ¼venli dÃ¶nÃ¼ÅŸtÃ¼rÃ¼cÃ¼ ---
    def _json_safe(self, obj):
        # numpy sayÄ±larÄ±
        if isinstance(obj, (np.integer,)):
            return int(obj)
        if isinstance(obj, (np.floating,)):
            return float(obj)
        if isinstance(obj, (np.ndarray,)):
            return obj.tolist()
        # torch tensor
        if isinstance(obj, torch.Tensor):
            return obj.detach().cpu().tolist()
        # pandas zaman tipleri
        if isinstance(obj, pd.Timestamp):
            return obj.isoformat()
        # diÄŸer yaygÄ±n yapÄ±lar
        if isinstance(obj, (set, tuple)):
            return list(obj)
        if isinstance(obj, bytes):
            return obj.decode("utf-8", "ignore")
        # fitz.Rect veya benzeri
        try:
            from fitz import Rect
            if isinstance(obj, Rect):
                return [float(obj.x0), float(obj.y0), float(obj.x1), float(obj.y1)]
        except Exception:
            pass
        # son Ã§are: str
        return str(obj)

    def process_pdf_with_real_replacement(self,
                                          pdf_file,
                                          confidence_threshold: float,
                                          replacement_strategy: str,
                                          custom_replacements: str,
                                          enable_logging: bool,
                                          enable_debug: bool,
                                          conversion_method: str,
                                          progress=gr.Progress()) -> Tuple[Optional[str], str, str, pd.DataFrame, str]:
        """
        GeliÅŸmiÅŸ PDF iÅŸleme - GERÃ‡EK deÄŸiÅŸtirme ile (Custom NER + Custom Lists + TutarlÄ± deÄŸiÅŸtirme + Karakter koruma)
        """
        if pdf_file is None:
            return None, "âŒ LÃ¼tfen bir PDF dosyasÄ± yÃ¼kleyin.", "", pd.DataFrame(), ""

        if self.ner_pipeline is None:
            return None, "âŒ NER modeli yÃ¼klenemedi. Model yolunu kontrol edin.", "", pd.DataFrame(), ""

        # Her yeni iÅŸlemde cache'i temizle
        self.replacement_cache.clear()

        debug_info = ""

        try:
            progress(0.05, desc="Dosya hazÄ±rlanÄ±yor...")

            # Dosya yollarÄ±
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            base_in = os.path.basename(pdf_file.name if hasattr(pdf_file, "name") else str(pdf_file))
            input_filename = f"input_{timestamp}_{base_in}"
            output_filename = f"anonymized_{timestamp}_{base_in}"

            input_path = os.path.join("uploads", input_filename)
            output_path = os.path.join("outputs", output_filename)

            # YÃ¼klenen dosyayÄ± kopyala
            shutil.copy2(pdf_file.name if hasattr(pdf_file, "name") else str(pdf_file), input_path)

            progress(0.1, desc="PDF analiz ediliyor...")

            # 1. PDF'ten metin ve pozisyonlarÄ± Ã§Ä±kar
            text_blocks = self.extract_text_with_positions(input_path)
            full_text = " ".join([block['text'] for block in text_blocks])

            if not full_text.strip():
                return None, "âš ï¸ PDF'den metin Ã§Ä±karÄ±lamadÄ±.", "", pd.DataFrame(), "Metin Ã§Ä±karÄ±lamadÄ±."

            progress(0.2, desc="NER analizi yapÄ±lÄ±yor...")

            # 2. Custom NER model ile analiz (sadece TC kimlik iÃ§in regex)
            entities_detected = self.extract_entities_with_custom_model(full_text, text_blocks, confidence_threshold,
                                                                        progress)

            if not entities_detected:
                return None, "âš ï¸ PDF'de kiÅŸisel bilgi tespit edilmedi.", "", pd.DataFrame(), "HiÃ§bir entity tespit edilmedi."

            progress(0.4, desc="DeÄŸiÅŸtirme stratejisi uygulanÄ±yor...")

            # 3. DeÄŸiÅŸtirme stratejisini uygula (tutarlÄ± + karakter sayÄ±sÄ± koruma)
            processed_entities = self.apply_replacement_strategy_consistent(
                entities_detected,
                replacement_strategy,
                custom_replacements or ""
            )

            progress(0.5, desc="PDF'te deÄŸiÅŸiklikler uygulanÄ±yor...")

            # 4. Font korumalÄ± PDF deÄŸiÅŸtirme
            success = self.perform_font_preserving_replacement(
                input_path,
                processed_entities,
                output_path,
                text_blocks,
                progress
            )

            if not success:
                return None, "âŒ PDF deÄŸiÅŸtirme iÅŸlemi baÅŸarÄ±sÄ±z oldu.", "", pd.DataFrame(), "DeÄŸiÅŸtirme baÅŸarÄ±sÄ±z"

            progress(0.8, desc="SonuÃ§lar doÄŸrulanÄ±yor...")

            # 5. DeÄŸiÅŸtirmeleri doÄŸrula
            validation_result = self.validate_pdf_changes(output_path, processed_entities)
            debug_info = self.format_debug_info(validation_result, processed_entities)

            progress(0.9, desc="Ä°statistikler oluÅŸturuluyor...")

            # 6. Ä°statistikleri oluÅŸtur
            stats_df = self.create_detailed_statistics(processed_entities, validation_result)
            summary = self.generate_detailed_summary(processed_entities, validation_result, input_filename)

            # 7. Loglama
            if enable_logging:
                self.log_processing_with_validation(input_filename, processed_entities, validation_result)

            progress(1.0, desc="TamamlandÄ±!")

            # BaÅŸarÄ± mesajÄ±
            success_rate = validation_result.get('successfully_replaced', 0)
            total_entities = len(processed_entities)
            status_msg = f"âœ… Ä°ÅŸlem tamamlandÄ±! {success_rate}/{total_entities} deÄŸiÅŸtirme baÅŸarÄ±lÄ±."

            return output_path, status_msg, summary, stats_df, (debug_info if enable_debug else "")

        except Exception as e:
            self.logger.error(f"PDF iÅŸleme hatasÄ±: {e}", exc_info=True)
            error_msg = f"âŒ Kritik hata: {str(e)}"
            return None, error_msg, "", pd.DataFrame(), f"Hata detayÄ±: {str(e)}"



    def extract_entities_with_custom_model(self, full_text: str, text_blocks: List[Dict],
                                           confidence_threshold: float, progress) -> List[Dict]:
        """Custom NER model ile entity tespiti + TC kimlik iÃ§in regex"""
        try:
            # Metni parÃ§alara bÃ¶l (model token limitini aÅŸmamak iÃ§in)
            max_length = 512
            text_chunks = []
            chunk_start = 0

            while chunk_start < len(full_text):
                chunk_end = min(chunk_start + max_length, len(full_text))

                # Kelime ortasÄ±nda kesmemek iÃ§in
                if chunk_end < len(full_text):
                    last_space = full_text.rfind(' ', chunk_start, chunk_end)
                    if last_space > chunk_start:
                        chunk_end = last_space

                chunk_text = full_text[chunk_start:chunk_end]
                text_chunks.append({
                    'text': chunk_text,
                    'start_offset': chunk_start,
                    'end_offset': chunk_end
                })
                chunk_start = chunk_end

            progress(0.25, desc=f"NER analizi ({len(text_chunks)} parÃ§a)...")

            all_entities = []

            # Her parÃ§a iÃ§in NER Ã§alÄ±ÅŸtÄ±r
            for i, chunk in enumerate(text_chunks):
                try:
                    results = self.ner_pipeline(chunk['text'])

                    for result in results:
                        if result['score'] >= confidence_threshold:
                            # Global pozisyonu hesapla
                            entity_start = chunk['start_offset'] + result['start']
                            entity_end = chunk['start_offset'] + result['end']

                            # Text block'ta karÅŸÄ±lÄ±k gelen pozisyonu bul
                            text_block_info = self.find_text_block_for_position(
                                entity_start, entity_end, text_blocks, full_text
                            )

                            entity_dict = {
                                'entity': self.map_model_label_to_type(result['entity_group']),
                                'word': result['word'],
                                'start': entity_start,
                                'end': entity_end,
                                'score': result['score'],
                                'method': 'custom_ner',
                                'text_block_info': text_block_info
                            }
                            all_entities.append(entity_dict)

                except Exception as e:
                    self.logger.warning(f"Chunk {i} iÅŸlenirken hata: {e}")
                    continue

            progress(0.3, desc="TC kimlik regex kontrolÃ¼...")

            # Sadece TC kimlik iÃ§in regex tespiti
            tc_entities = self.detect_tc_kimlik_with_blocks(full_text, text_blocks)

            # BirleÅŸtir ve temizle
            combined_entities = self.merge_and_clean_entities(all_entities + tc_entities, confidence_threshold)

            self.logger.info(f"Toplam {len(combined_entities)} entity tespit edildi")
            return combined_entities

        except Exception as e:
            self.logger.error(f"Custom NER analiz hatasÄ±: {e}")
            return []

    def detect_tc_kimlik_with_blocks(self, full_text: str, text_blocks: List[Dict]) -> List[Dict]:
        """Sadece TC Kimlik iÃ§in regex tespiti"""
        tc_entities = []

        # TC Kimlik pattern
        tc_pattern = r'\b[1-9][0-9]{9}[02468]\b'
        for match in re.finditer(tc_pattern, full_text):
            tc_no = match.group()
            if self.validate_turkish_id(tc_no):
                text_block_info = self.find_text_block_for_position(
                    match.start(), match.end(), text_blocks, full_text
                )

                tc_entities.append({
                    'entity': 'tc_kimlik',
                    'word': tc_no,
                    'start': match.start(),
                    'end': match.end(),
                    'score': 0.95,
                    'method': 'regex_validated',
                    'text_block_info': text_block_info
                })

        return tc_entities

    def map_model_label_to_type(self, model_label: str) -> str:
        """Model etiketlerini uygulama tÃ¼rlerine eÅŸle"""
        # Modelinizin Ã§Ä±ktÄ± etiketlerine gÃ¶re bu mapping'i gÃ¼ncelleyin
        label_mapping = {
            'PERSON': 'ad_soyad',
            'PER': 'ad_soyad',
            'B-PERSON': 'ad_soyad',
            'I-PERSON': 'ad_soyad',
            'PHONE': 'telefon',
            'PHONE_NUMBER': 'telefon',
            'EMAIL': 'email',
            'ADDRESS': 'adres',
            'ORGANIZATION': 'sirket',
            'ORG': 'sirket',
            'MONEY': 'para',
            'DATE': 'tarih',
            'ID_NUMBER': 'tc_kimlik',
            'NATIONAL_ID': 'tc_kimlik'
        }
        return label_mapping.get(model_label.upper(), model_label.lower())

    def find_text_block_for_position(self, start_pos: int, end_pos: int,
                                     text_blocks: List[Dict], full_text: str) -> Dict:
        """Verilen pozisyon iÃ§in text block bilgilerini bul"""
        current_pos = 0

        for block in text_blocks:
            block_text = block['text']
            block_start = current_pos
            block_end = current_pos + len(block_text)

            # Entity bu block iÃ§inde mi?
            if start_pos >= block_start and end_pos <= block_end + 1:
                # Block iÃ§indeki relatif pozisyonu hesapla
                relative_start = start_pos - block_start
                relative_end = end_pos - block_start

                return {
                    'page': block['page'],
                    'bbox': block['bbox'],
                    'font': block['font'],
                    'size': block['size'],
                    'flags': block['flags'],
                    'color': block['color'],
                    'relative_start': relative_start,
                    'relative_end': relative_end,
                    'block_text': block_text
                }

            current_pos = block_end + 1  # +1 for space/newline

        # BulunamadÄ± ise default deÄŸer
        return {
            'page': 0,
            'bbox': (0, 0, 100, 20),
            'font': 'Arial',
            'size': 12,
            'flags': 0,
            'color': 0,
            'relative_start': 0,
            'relative_end': 0,
            'block_text': ''
        }

    def perform_font_preserving_replacement(self, input_path: str, entities: List[Dict],
                                            output_path: str, text_blocks: List[Dict], progress) -> bool:
        """Font Ã¶zelliklerini koruyarak PDF deÄŸiÅŸtirme"""
        try:
            doc = fitz.open(input_path)
            total_replacements = 0

            progress(0.6, desc="Font bilgileri korunarak deÄŸiÅŸtiriliyor...")

            # Sayfa bazÄ±nda entity'leri grupla
            entities_by_page = {}
            for entity in entities:
                page_num = entity.get('text_block_info', {}).get('page', 0)
                if page_num not in entities_by_page:
                    entities_by_page[page_num] = []
                entities_by_page[page_num].append(entity)

            # Her sayfa iÃ§in iÅŸlem yap
            for page_num in range(len(doc)):
                if page_num not in entities_by_page:
                    continue

                page = doc.load_page(page_num)
                page_entities = entities_by_page[page_num]

                progress(0.6 + (page_num / len(doc)) * 0.2,
                         desc=f"Sayfa {page_num + 1}/{len(doc)} iÅŸleniyor...")

                # Entity'leri pozisyona gÃ¶re sÄ±rala (tersten - sondan baÅŸa)
                page_entities.sort(key=lambda x: x.get('start', 0), reverse=True)

                for entity in page_entities:
                    success = self.replace_entity_with_font_preservation(page, entity)
                    if success:
                        total_replacements += 1

            doc.save(output_path)
            doc.close()

            self.logger.info(f"Font korumalÄ± deÄŸiÅŸtirme: {total_replacements} baÅŸarÄ±lÄ±")
            return total_replacements > 0

        except Exception as e:
            self.logger.error(f"Font korumalÄ± deÄŸiÅŸtirme hatasÄ±: {e}")
            return False

    def replace_entity_with_font_preservation(self, page, entity: Dict) -> bool:
        """Tek bir entity'yi font Ã¶zelliklerini koruyarak deÄŸiÅŸtir (quad tabanlÄ± arama, gÃ¼venli akÄ±ÅŸ)."""
        try:
            # 1) GÃ¼venli Ã§ekimler
            original_text = (entity.get('word') or '').strip()
            replacement_text = (entity.get('replacement') or original_text).strip()
            if not original_text or replacement_text == original_text:
                return False

            text_block_info = entity.get('text_block_info') or {}
            bbox = text_block_info.get('bbox')
            if not bbox:
                self.logger.warning("replace_entity_with_font_preservation: bbox yok")
                return False

            block_text = text_block_info.get('block_text', '')
            rel_s = int(text_block_info.get('relative_start', 0))
            rel_e = int(text_block_info.get('relative_end', 0))
            block_slice = block_text[rel_s:rel_e] if (0 <= rel_s <= len(block_text) and 0 <= rel_e <= len(block_text)) else ''
            search_text = (block_slice or original_text).strip()

            # 2) Aday sorgular
            candidates = self._candidate_queries(search_text) or [search_text]

            # 3) Quad arama (yakÄ±n bbox'a gÃ¶re)
            hit_quads = None
            for q in candidates:
                hit_quads = self._search_quads_near(page, q, bbox)
                if hit_quads:
                    break

            # Basit fallback: page.search_for
            if not hit_quads:
                # === CHAR-LEVEL FALLBACK ===
                char_rect = self._rect_from_block_slice_chars(page, text_block_info)
                if char_rect:
                    rects = [char_rect]
                else:
                    self.logger.warning(f"Metin sayfada bulunamadÄ± (quad/search): {search_text}")
                    return False
            else:
                rects = self._rects_from_hit(hit_quads)

            if not rects:
                self.logger.warning("Hit bulundu ama rect Ã§Ä±karÄ±lamadÄ±")
                return False

            # Redaksiyon
            for r in rects:
                bg = self._sample_background_color(page, r, margin=1.0, ring=8)
                page.add_redact_annot(r, fill=bg)
            page.apply_redactions() 


            # 5) YazÄ± yerleÅŸtirme (ilk rect)
            first_rect = rects[0]

            font_size = float(text_block_info.get('size', 12.0))
            font_color = text_block_info.get('color', 0)
            default_font = 'helv'

            # Renk int â†’ RGB
            if isinstance(font_color, int):
                rgb_color = (
                    ((font_color >> 16) & 255) / 255.0,
                    ((font_color >> 8) & 255) / 255.0,
                    (font_color & 255) / 255.0
                )
            else:
                rgb_color = (0, 0, 0)

            # GeniÅŸliÄŸe gÃ¶re font kÃ¼Ã§Ã¼lt
            rect_width = first_rect.width
            text_width = fitz.get_text_length(replacement_text, fontname=default_font, fontsize=font_size)
            if text_width > rect_width * 1.1:
                font_size = max(font_size * (rect_width / max(text_width, 1e-6)) * 0.9, 6)

            insert_point = (first_rect.x0, first_rect.y1 - 2)
            page.insert_text(
                insert_point,
                replacement_text,
                fontsize=font_size,
                fontname=default_font,
                color=rgb_color,
                render_mode=0
            )

            self.logger.debug(
                f"DeÄŸiÅŸtirildi: '{original_text}' -> '{replacement_text}' (font={default_font}, size={font_size:.2f})"
            )
            return True

        except Exception as e:
            self.logger.error(f"Entity deÄŸiÅŸtirme hatasÄ±: {e}", exc_info=True)
            return False
        
    def _sample_background_color(self, page, rect, margin=1.5, ring=4) -> tuple:
        """
        DikdÃ¶rtgenin Ã§evresinden (ring) arka plan rengi Ã¶rnekler ve (r,g,b) 0..1 dÃ¶ndÃ¼rÃ¼r.
        Ã‡ok koyu (muhtemelen yazÄ±) pikselleri filtreler.
        """
        try:
            r = fitz.Rect(rect)
            outer = fitz.Rect(r).inflate(margin + ring)
            inner = fitz.Rect(r).inflate(margin)

            pm = page.get_pixmap(clip=outer, alpha=False)
            w, h, n = pm.width, pm.height, pm.n  # n: kanal sayÄ±sÄ± (3 veya 4)

            import numpy as np
            arr = np.frombuffer(pm.samples, dtype=np.uint8).reshape(h, w, n)
            rgb = arr[:, :, :3] if n >= 3 else np.repeat(arr, 3, axis=2)

            # outer koordinatlarÄ±ndan innerâ€™a piksel sÄ±nÄ±rlarÄ±nÄ± hesapla
            sx = w / max(outer.width, 1e-6)
            sy = h / max(outer.height, 1e-6)
            ix0 = max(0, min(w, int((inner.x0 - outer.x0) * sx)))
            iy0 = max(0, min(h, int((inner.y0 - outer.y0) * sy)))
            ix1 = max(0, min(w, int((inner.x1 - outer.x1) * sx)))
            iy1 = max(0, min(h, int((inner.y1 - outer.y0) * sy)))  # dikkat: y0

            mask = np.ones((h, w), dtype=bool)
            mask[iy0:iy1, ix0:ix1] = False  # iÃ§teki alanÄ± Ã§Ä±kar â†’ sadece halka

            samples = rgb[mask]
            if samples.size == 0:
                samples = rgb.reshape(-1, 3)

            # metin / kenar etkisini azalt: Ã§ok koyu pikselleri at
            lum = 0.2126 * samples[:, 0] + 0.7152 * samples[:, 1] + 0.0722 * samples[:, 2]
            use = lum > 60  # eÅŸik: 0..255
            if np.sum(use) >= 50:
                samples = samples[use]

            med = np.median(samples, axis=0)
            return (float(med[0] / 255.0), float(med[1] / 255.0), float(med[2] / 255.0))
        except Exception:
            # sorun olursa beyazÄ± dÃ¼ÅŸmeyelim, hafif gri daha az sÄ±rÄ±tÄ±yor
            return (0.96, 0.96, 0.96)


    def validate_turkish_id(self, tc_no: str) -> bool:
        """TC kimlik validasyonu"""
        if not tc_no or len(tc_no) != 11 or not tc_no.isdigit():
            return False
        if tc_no[0] == '0':
            return False
        digits = [int(d) for d in tc_no]
        odd_sum = sum(digits[i] for i in range(0, 9, 2))
        even_sum = sum(digits[i] for i in range(1, 8, 2))
        check_digit_10 = (odd_sum * 7 - even_sum) % 10
        if check_digit_10 != digits[9]:
            return False
        check_digit_11 = sum(digits[:10]) % 10
        if check_digit_11 != digits[10]:
            return False
        return True

    def merge_and_clean_entities(self, entities: List[Dict], confidence_threshold: float) -> List[Dict]:
        """Entity'leri birleÅŸtir ve temizle"""
        seen = set()
        cleaned = []
        for entity in entities:
            key = (entity.get('start', 0), entity.get('end', 0), entity.get('word', ''))
            if key not in seen:
                seen.add(key)
                cleaned.append(entity)
        filtered = [e for e in cleaned if e.get('score', 0) >= confidence_threshold]
        return sorted(filtered, key=lambda x: x.get('start', 0))

    def generate_consistent_replacement(self, original_text: str, entity_type: str, strategy: str,
                                        custom_replacements: Dict) -> str:
        """
        AynÄ± orijinal metin iÃ§in tutarlÄ± deÄŸiÅŸtirme Ã¼retir.
        'Sahte DeÄŸerler' modunda SIKI LÄ°STE KURALI uygulanÄ±r:
        - Tam uzunluk eÅŸleÅŸmesi olan Ã¶rnek varsa listeden seÃ§ilir.
        - Yoksa DEÄžÄ°ÅžTÄ°RME YAPILMAZ (orijinal bÄ±rakÄ±lÄ±r).
        """
        cache_key = f"{original_text}_{entity_type}_{strategy}"
        if cache_key in self.replacement_cache:
            return self.replacement_cache[cache_key]

        target_length = len(original_text)

        if strategy == "Maskeleme (*)":
            replacement = "*" * target_length

        elif strategy == "Genel DeÄŸerler":
            # Genel placeholder'lar KALDI; ama burada da listeden seÃ§me zorunluluÄŸu yok.
            generic_map = {
                'ad_soyad': '[Ä°SÄ°M]', 'tc_kimlik': '[TC KÄ°MLÄ°K]', 'telefon': '[TELEFON]',
                'adres': '[ADRES]', 'para': '[PARA]', 'tarih': '[TARÄ°H]',
                'email': '[E-POSTA]', 'sirket': '[ÅžÄ°RKET]', 'iban': '[IBAN]'
            }
            base = generic_map.get(entity_type, f'[{entity_type.upper()}]')
            # Karakter eÅŸitleme olmadan dÃ¼z kesme/maskeleme istemiyorsan burayÄ± da sÄ±kÄ±laÅŸtÄ±rabiliriz.
            # Åžimdilik: tam uyar ise kullan, deÄŸilse kÄ±salt.
            replacement = base[:target_length] if len(base) >= target_length else base + ("*" * (target_length - len(base)))

        elif strategy == "Sahte DeÄŸerler":
            # 1) Ã–nce custom_replacements, ama YALNIZCA tam uzunlukta ise kabul
            if entity_type in custom_replacements:
                cv = str(custom_replacements[entity_type])
                if len(cv) == target_length:
                    replacement = cv
                else:
                    # SÄ±kÄ± mod: uzunluk tutmuyor â†’ deÄŸiÅŸtirme yapma
                    replacement = original_text
            else:
                # 2) YalnÄ±zca listelerden tam eÅŸleÅŸme
                try:
                    replacement = self.generate_text_with_exact_length(target_length, entity_type, original_text)
                except KeyError:
                    # SÄ±kÄ± mod: liste yoksa deÄŸiÅŸtirme yapma
                    replacement = original_text

        else:
            replacement = original_text

        # DeÄŸiÅŸiklik olduysa cache'le
        if replacement != original_text:
            self.replacement_cache[cache_key] = replacement
        return replacement


    def apply_replacement_strategy_consistent(self, entities: List[Dict], strategy: str, custom_replacements: str) -> \
    List[Dict]:
        """TutarlÄ± deÄŸiÅŸtirme stratejisini uygula"""

        # Custom replacements parse et
        custom_dict = {}
        if custom_replacements and custom_replacements.strip():
            try:
                custom_dict = json.loads(custom_replacements)
            except json.JSONDecodeError as e:
                self.logger.warning(f"Custom replacements parse hatasÄ±: {e}")

        processed = []
        for entity in entities:
            e = entity.copy()
            original = e.get('word', '').strip()
            entity_type = e.get('entity', '').strip()

            # TutarlÄ± deÄŸiÅŸtirme Ã¼ret (Custom Lists kullanarak)
            replacement = self.generate_consistent_replacement(
                original, entity_type, strategy, custom_dict
            )

            e['replacement'] = replacement
            processed.append(e)

        return processed

    def validate_pdf_changes(self, output_path: str, entities: List[Dict]) -> Dict:
        """PDF'teki deÄŸiÅŸiklikleri doÄŸrula"""
        try:
            doc = fitz.open(output_path)
            full_text = ""
            for page_num in range(len(doc)):
                page = doc.load_page(page_num)
                full_text += page.get_text()
            doc.close()

            validation_result = {
                'total_entities': len(entities),
                'successfully_replaced': 0,
                'still_present': [],
                'replacement_found': [],
                'partial_replacements': []
            }
            for entity in entities:
                original = entity.get('word', '').strip()
                replacement = entity.get('replacement', original).strip()
                if original in full_text:
                    validation_result['still_present'].append(original)
                else:
                    validation_result['successfully_replaced'] += 1
                if replacement in full_text and replacement != original:
                    validation_result['replacement_found'].append(replacement)
            return validation_result
        except Exception as e:
            self.logger.error(f"Validasyon hatasÄ±: {e}")
            return {'error': str(e)}

    def format_debug_info(self, validation_result: Dict, entities: List[Dict]) -> str:
        """Debug bilgilerini formatla"""
        if 'error' in validation_result:
            return f"âŒ Validasyon hatasÄ±: {validation_result['error']}"

        # Custom Lists kullanÄ±m istatistikleri
        list_usage_stats = {}
        for entity_type, lengths_dict in self.organized_data.items():
            total_samples = sum(len(samples) for samples in lengths_dict.values())
            if total_samples > 0:
                list_usage_stats[entity_type] = {
                    'total_samples': total_samples,
                    'length_variants': len(lengths_dict)
                }

        debug_info = f"""
## ðŸ” Debug Bilgileri

### DeÄŸiÅŸtirme SonuÃ§larÄ±:
- **Toplam Entity**: {validation_result['total_entities']}
- **BaÅŸarÄ±lÄ± DeÄŸiÅŸtirme**: {validation_result['successfully_replaced']}
- **Hala Mevcut**: {len(validation_result.get('still_present', []))}
- **Yeni DeÄŸerler Bulundu**: {len(validation_result.get('replacement_found', []))}

### Custom Lists Ä°statistikleri:
- **Cache Boyutu**: {len(self.replacement_cache)}
- **KullanÄ±lan Entity Tipleri**: {len([e for e in entities if e.get('entity') in self.organized_data])}

### Veri Listesi KapsamÄ±:
"""
        for entity_type, stats in list_usage_stats.items():
            debug_info += f"- **{entity_type}**: {stats['total_samples']} Ã¶rnek, {stats['length_variants']} farklÄ± uzunluk\n"

        debug_info += f"""
### Hala Mevcut Metinler:
{validation_result.get('still_present', [])[:5]}

### Bulunan Yeni DeÄŸerler:
{validation_result.get('replacement_found', [])[:5]}

### Model Bilgileri:
- **Model Yolu**: {self.model_path}
- **Model Durumu**: {'âœ… YÃ¼klendi' if self.ner_pipeline else 'âŒ YÃ¼klenemedi'}
- **Veri KaynaÄŸÄ±**: Custom Lists (datalar.py)
        """.strip()
        return debug_info

    def create_detailed_statistics(self, entities: List[Dict], validation_result: Dict) -> pd.DataFrame:
        """DetaylÄ± istatistik tablosu"""
        if not entities:
            return pd.DataFrame(columns=['Veri TÃ¼rÃ¼', 'Tespit', 'DeÄŸiÅŸtirildi', 'BaÅŸarÄ± OranÄ±', 'Ã–rnek'])

        stats = {}
        for entity in entities:
            etype = entity['entity']
            if etype not in stats:
                stats[etype] = {'detected': 0, 'examples': [], 'originals': [], 'replacements': []}
            stats[etype]['detected'] += 1
            stats[etype]['originals'].append(entity.get('word', ''))
            stats[etype]['replacements'].append(entity.get('replacement', ''))
            if len(stats[etype]['examples']) < 2:
                stats[etype]['examples'].append(entity.get('word', ''))

        rows = []
        names = {
            'ad_soyad': 'ðŸ‘¤ Ad Soyad',
            'tc_kimlik': 'ðŸ†” TC Kimlik',
            'telefon': 'ðŸ“± Telefon',
            'adres': 'ðŸ“ Adres',
            'para': 'ðŸ’° Para',
            'tarih': 'ðŸ“… Tarih',
            'email': 'ðŸ“§ E-posta',
            'sirket': 'ðŸ¢ Åžirket'
        }
        for etype, data in stats.items():
            successful = 0
            for original in data['originals']:
                if original not in validation_result.get('still_present', []):
                    successful += 1
            success_rate = (successful / data['detected'] * 100) if data['detected'] > 0 else 0
            rows.append({
                'Veri TÃ¼rÃ¼': names.get(etype, etype.title()),
                'Tespit': data['detected'],
                'DeÄŸiÅŸtirildi': successful,
                'BaÅŸarÄ± OranÄ±': f"{success_rate:.1f}%",
                'Ã–rnek': ', '.join(data['examples'][:2])
            })
        return pd.DataFrame(rows)

    def generate_detailed_summary(self, entities: List[Dict], validation_result: Dict, filename: str) -> str:
        """DetaylÄ± Ã¶zet oluÅŸtur"""
        if not entities:
            return "âŒ HiÃ§bir kiÅŸisel bilgi tespit edilmedi."

        total_entities = len(entities)
        successful = validation_result.get('successfully_replaced', 0)
        still_present = len(validation_result.get('still_present', []))
        success_rate = (successful / total_entities * 100) if total_entities > 0 else 0

        if success_rate >= 90:
            status_emoji = "ðŸŸ¢";
            status_text = "MÃ¼kemmel"
        elif success_rate >= 70:
            status_emoji = "ðŸŸ¡";
            status_text = "Ä°yi"
        else:
            status_emoji = "ðŸ”´";
            status_text = "Dikkat Gerekli"

        unique_replacements = len(self.replacement_cache)

        # Custom Lists kullanÄ±m analizi
        custom_usage = 0
        for entity in entities:
            entity_type = entity.get('entity')
            original_length = len(entity.get('word', ''))
            if (entity_type in self.organized_data and
                    original_length in self.organized_data[entity_type] and
                    self.organized_data[entity_type][original_length]):
                custom_usage += 1

        summary = f"""
## ðŸ“Š DetaylÄ± Ä°ÅŸlem Raporu

**Dosya:** {filename}  
**Tarih:** {datetime.now().strftime('%d.%m.%Y %H:%M')}

### {status_emoji} Genel BaÅŸarÄ±: {status_text} ({success_rate:.1f}%)

### ðŸŽ¯ DeÄŸiÅŸtirme SonuÃ§larÄ±
- **Toplam Tespit:** {total_entities} adet
- **BaÅŸarÄ±lÄ± DeÄŸiÅŸtirme:** {successful} adet  
- **Hala Mevcut:** {still_present} adet
- **TutarlÄ± DeÄŸiÅŸtirmeler:** {unique_replacements} adet
- **Custom Lists KullanÄ±mÄ±:** {custom_usage}/{total_entities} ({(custom_usage / total_entities * 100):.1f}%) 

### ðŸ“ˆ Performans Analizi
""".strip()
        if success_rate >= 90:
            summary += "\n\nâœ… **Harika!** Neredeyse tÃ¼m kiÅŸisel bilgiler baÅŸarÄ±yla deÄŸiÅŸtirildi."
        elif success_rate >= 70:
            summary += "\n\nâš ï¸ **Ä°yi performans** ancak bazÄ± bilgiler deÄŸiÅŸtirilemedi. Manuel kontrol Ã¶nerilir."
        else:
            summary += "\n\nðŸš¨ **Dikkat!** Ã‡oÄŸu bilgi deÄŸiÅŸtirilemedi. FarklÄ± yÃ¶ntem denemeyi dÃ¼ÅŸÃ¼nÃ¼n."

        if still_present > 0:
            still_present_list = validation_result.get('still_present', [])[:3]
            summary += "\n\n### ðŸ” DeÄŸiÅŸtirilemeyen Ã–rnekler:\n"
            for item in still_present_list:
                summary += f"- `{item}`\n"

        summary += f"\n\n### ðŸ”„ TutarlÄ±lÄ±k & Custom Lists Bilgisi:\n- AynÄ± metinler iÃ§in tutarlÄ± deÄŸiÅŸtirmeler uygulandÄ±.\n- Karakter sayÄ±sÄ± korumasÄ± aktif.\n- Custom veri listeleri kullanÄ±ldÄ± (datalar.py).\n- TC kimlik iÃ§in regex + geÃ§erli Ã¼retim."
        return summary

    def log_processing_with_validation(self, filename: str, entities: List[Dict], validation_result: Dict):
        log_entry = {
            'timestamp': datetime.now().isoformat(),
            'filename': filename,
            'total_entities': len(entities),
            'successful_replacements': validation_result.get('successfully_replaced', 0),
            'still_present_count': len(validation_result.get('still_present', [])),
            'success_rate': (
                        validation_result.get('successfully_replaced', 0) / len(entities) * 100) if entities else 0,
            'unique_replacements': len(self.replacement_cache),
            'custom_lists_version': 'datalar.py',
            'entities': entities,
            'validation_result': validation_result
        }
        log_file = f"logs/detailed_session_{datetime.now().strftime('%Y%m%d')}.json"
        logs = []
        if os.path.exists(log_file):
            try:
                with open(log_file, 'r', encoding='utf-8') as f:
                    logs = json.load(f)
            except Exception:
                logs = []
        logs.append(log_entry)
        with open(log_file, 'w', encoding='utf-8') as f:
            json.dump(logs, f, ensure_ascii=False, indent=2, default=self._json_safe)

    def get_processing_history(self) -> pd.DataFrame:
        """Ä°ÅŸlem geÃ§miÅŸini al"""
        try:
            log_files = []
            for i in range(7):
                date_str = (datetime.now() - pd.Timedelta(days=i)).strftime('%Y%m%d')
                log_file = f"logs/detailed_session_{date_str}.json"
                if os.path.exists(log_file):
                    log_files.append(log_file)
            all_logs = []
            for log_file in log_files:
                with open(log_file, 'r', encoding='utf-8') as f:
                    logs = json.load(f)
                    all_logs.extend(logs)
            if not all_logs:
                return pd.DataFrame(
                    columns=['Tarih', 'Dosya', 'Toplam Tespit', 'BaÅŸarÄ±lÄ±', 'BaÅŸarÄ± OranÄ±', 'Veri KaynaÄŸÄ±'])
            rows = []
            for log in all_logs[-50:]:
                timestamp = datetime.fromisoformat(log['timestamp'])
                rows.append({
                    'Tarih': timestamp.strftime('%d.%m.%Y %H:%M'),
                    'Dosya': log['filename'],
                    'Toplam Tespit': log['total_entities'],
                    'BaÅŸarÄ±lÄ±': log.get('successful_replacements', 0),
                    'BaÅŸarÄ± OranÄ±': f"{log.get('success_rate', 0):.1f}%",
                    'Veri KaynaÄŸÄ±': log.get('custom_lists_version', 'Custom Lists')
                })
            return pd.DataFrame(rows)
        except Exception:
            return pd.DataFrame(columns=['Tarih', 'Dosya', 'Toplam Tespit', 'BaÅŸarÄ±lÄ±', 'BaÅŸarÄ± OranÄ±', 'Veri KaynaÄŸÄ±'])

    # -----------------------------
    # Gradio UI
    # -----------------------------
    def create_enhanced_interface(self):
        """GeliÅŸmiÅŸ Gradio arayÃ¼zÃ¼"""
        css = """
        .gradio-container { font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif; }
        .debug-info { background-color: #f8f9fa; padding: 10px; border-radius: 5px; font-family: monospace; font-size: 12px; }
        .model-status { padding: 10px; border-radius: 5px; margin: 10px 0; }
        .model-loaded { background-color: #d4edda; border: 1px solid #c3e6cb; color: #155724; }
        .model-error { background-color: #f8d7da; border: 1px solid #f5c6cb; color: #721c24; }
        """

        # Custom Lists istatistikleri
        total_samples = 0
        for entity_type, lengths_dict in self.organized_data.items():
            total_samples += sum(len(samples) for samples in lengths_dict.values())

        with gr.Blocks(css=css, title="PDF KiÅŸisel Bilgi AnonimleÅŸtirici - Custom Lists",
                       theme=gr.themes.Soft()) as interface:
            # Model durumu gÃ¶ster
            model_status = "âœ… Custom NER Model YÃ¼klendi" if self.ner_pipeline else "âŒ Model YÃ¼klenemedi"
            model_class = "model-loaded" if self.ner_pipeline else "model-error"

            gr.Markdown(f"""
            # ðŸ” PDF KiÅŸisel Bilgi AnonimleÅŸtirici â€” Custom Data Lists
            YÃ¼klediÄŸiniz PDF'teki kiÅŸisel bilgileri **Ã¶zel modelinizle tespit eder** ve **kendi veri listelerinizle tutarlÄ± + karakter sayÄ±sÄ± korumalÄ± deÄŸiÅŸtirme** yapar.

            <div class="model-status {model_class}">
            ðŸ¤– **Model Durumu**: {model_status}<br>
            ðŸ“ **Model Yolu**: {self.model_path}<br>
            ðŸ“Š **Custom Lists**: {total_samples} toplam veri Ã¶rneÄŸi<br>
            ðŸ”§ **Ã–zellikler**: TutarlÄ± deÄŸiÅŸtirme, karakter sayÄ±sÄ± koruma, custom veri listeleri, TC kimlik regex
            </div>
            """)

            with gr.Tabs():
                # ------------------ Ana Ä°ÅŸlem Sekmesi ------------------
                with gr.TabItem("ðŸ“„ PDF Ä°ÅŸleme", elem_id="main-tab"):
                    with gr.Row():
                        with gr.Column(scale=1):
                            pdf_input = gr.File(
                                label="ðŸ“Ž PDF DosyasÄ± YÃ¼kleyin",
                                file_types=[".pdf"],
                                type="filepath"
                            )

                            gr.Markdown("### âš™ï¸ Ä°ÅŸlem AyarlarÄ±")

                            confidence_threshold = gr.Slider(
                                minimum=0.1, maximum=1.0, value=0.7, step=0.1,
                                label="ðŸŽ¯ GÃ¼ven EÅŸiÄŸi"
                            )

                            replacement_strategy = gr.Radio(
                                choices=["Maskeleme (*)", "Sahte DeÄŸerler", "Genel DeÄŸerler"],
                                value="Sahte DeÄŸerler",
                                label="ðŸ” DeÄŸiÅŸtirme Stratejisi",
                                info="Sahte DeÄŸerler: Custom Lists kullanÄ±lÄ±r"
                            )

                            with gr.Accordion("ðŸ§© Ã–zel DeÄŸer HaritasÄ± (JSON)", open=False):
                                gr.Markdown(
                                    "**Not**: Sistem Ã¶nce Custom Lists'ten uygun uzunlukta veri bulmaya Ã§alÄ±ÅŸÄ±r.")
                                example_json = {
                                    "ad_soyad": "Mehmet YÄ±lmaz",
                                    "telefon": "05551234567",
                                    "email": "anonim@example.com",
                                    "adres": "Ankara, TÃ¼rkiye"
                                }
                                gr.Code(value=json.dumps(example_json, ensure_ascii=False, indent=2), language="json")
                                custom_replacements = gr.Textbox(
                                    label="Ã–zel DeÄŸerler (JSON)",
                                    placeholder='{"ad_soyad": "Mehmet YÄ±lmaz", "telefon": "0555..."}',
                                    lines=5
                                )

                            enable_logging = gr.Checkbox(value=True, label="ðŸ§¾ Log kaydÄ± tut")
                            enable_debug = gr.Checkbox(value=False, label="ðŸž Debug bilgilerini gÃ¶ster")

                            process_btn = gr.Button(
                                "ðŸš€ Custom Lists ile Ä°ÅŸlemi BaÅŸlat",
                                variant="primary",
                                interactive=bool(self.ner_pipeline)
                            )

                            if not self.ner_pipeline:
                                gr.Markdown("âš ï¸ **UyarÄ±**: Model yÃ¼klenemediÄŸi iÃ§in iÅŸlem baÅŸlatÄ±lamaz.")

                        with gr.Column(scale=1):
                            output_pdf = gr.File(label="ðŸ“¤ AnonimleÅŸtirilmiÅŸ PDF", file_count="single")
                            status_text = gr.Markdown("â³ HenÃ¼z iÅŸlem yapÄ±lmadÄ±.")
                            summary_md = gr.Markdown("")
                            stats_df = gr.Dataframe(
                                headers=["Veri TÃ¼rÃ¼", "Tespit", "DeÄŸiÅŸtirildi", "BaÅŸarÄ± OranÄ±", "Ã–rnek"],
                                interactive=False)
                            debug_out = gr.Textbox(label="Debug", lines=15, visible=False)

                        # Buton-click baÄŸlama
                        def _wrap_process(pdf, thr, strat, custom_json, log_on, dbg_on, progress=gr.Progress()):
                            out_path, status, summary, df, dbg = self.process_pdf_with_real_replacement(
                                pdf, thr, strat, custom_json or "", log_on, dbg_on, "font_preserving", progress
                            )
                            # Debug gÃ¶rÃ¼nÃ¼rlÃ¼ÄŸÃ¼
                            return (
                                out_path,
                                status,
                                summary,
                                df,
                                gr.update(value=dbg, visible=bool(dbg_on))
                            )

                        process_btn.click(
                            _wrap_process,
                            inputs=[pdf_input, confidence_threshold, replacement_strategy, custom_replacements,
                                    enable_logging, enable_debug],
                            outputs=[output_pdf, status_text, summary_md, stats_df, debug_out],
                            api_name="process_pdf"
                        )

                    # ------------------ Custom Lists Ä°nceleme ------------------
                    with gr.TabItem("ðŸ“‹ Custom Lists Ä°nceleme"):
                        gr.Markdown("### Custom Lists Veri Ä°statistikleri")

                        # Veri listesi Ã¶zeti
                        list_summary = []
                        for entity_type, lengths_dict in self.organized_data.items():
                            total_samples = sum(len(samples) for samples in lengths_dict.values())
                            if total_samples > 0:
                                length_range = f"{min(lengths_dict.keys())}-{max(lengths_dict.keys())}" if lengths_dict else "N/A"
                                list_summary.append({
                                    'Veri TÃ¼rÃ¼': entity_type.replace('_', ' ').title(),
                                    'Toplam Ã–rnek': total_samples,
                                    'Uzunluk Ã‡eÅŸitliliÄŸi': len(lengths_dict),
                                    'Uzunluk AralÄ±ÄŸÄ±': length_range
                                })

                        summary_df_lists = gr.Dataframe(
                            value=pd.DataFrame(list_summary),
                            label="Veri Listesi Ã–zeti",
                            interactive=False
                        )

                        # DetaylÄ± gÃ¶rÃ¼ntÃ¼leme
                        with gr.Row():
                            entity_type_selector = gr.Dropdown(
                                choices=list(self.organized_data.keys()),
                                value=list(self.organized_data.keys())[0] if self.organized_data else None,
                                label="Veri TÃ¼rÃ¼ SeÃ§in"
                            )
                            length_selector = gr.Dropdown(label="Uzunluk SeÃ§in")

                        samples_display = gr.Textbox(
                            label="Ã–rnek Veriler",
                            lines=10,
                            interactive=False
                        )

                        def update_length_options(entity_type):
                            if entity_type and entity_type in self.organized_data:
                                lengths = sorted(self.organized_data[entity_type].keys())
                                return gr.update(choices=lengths, value=lengths[0] if lengths else None)
                            return gr.update(choices=[], value=None)

                        def display_samples(entity_type, length):
                            if (entity_type and length is not None and
                                    entity_type in self.organized_data and
                                    length in self.organized_data[entity_type]):
                                samples = self.organized_data[entity_type][length]
                                sample_text = "\n".join(samples[:50])  # Ä°lk 50 Ã¶rnek
                                if len(samples) > 50:
                                    sample_text += f"\n\n... ve {len(samples) - 50} Ã¶rnek daha"
                                return sample_text
                            return "SeÃ§ilen kategoride veri bulunamadÄ±."

                        entity_type_selector.change(
                            update_length_options,
                            inputs=[entity_type_selector],
                            outputs=[length_selector]
                        )

                        length_selector.change(
                            display_samples,
                            inputs=[entity_type_selector, length_selector],
                            outputs=[samples_display]
                        )

                        # Sayfa yÃ¼klendiÄŸinde ilk deÄŸerleri ayarla
                        interface.load(
                            update_length_options,
                            inputs=[entity_type_selector],
                            outputs=[length_selector]
                        )

                    # ------------------ Model Test ------------------
                    with gr.TabItem("ðŸ§ª Model Test"):
                        gr.Markdown("### Custom NER Model + TC Kimlik Regex + Custom Lists Testi")

                        test_text = gr.Textbox(
                            label="Test Metni",
                            placeholder="Ã–rnek: Ahmet YÄ±lmaz 12345678901 TC kimlik ile ahmet@email.com adresine mail gÃ¶nderdi.",
                            lines=5
                        )
                        test_confidence = gr.Slider(
                            minimum=0.1, maximum=1.0, value=0.5, step=0.1,
                            label="Test GÃ¼ven EÅŸiÄŸi"
                        )
                        test_btn = gr.Button("ðŸ” Test Et", variant="secondary")
                        test_results = gr.JSON(label="Test SonuÃ§larÄ±")

                        def test_model_with_custom_lists(text, conf_threshold):
                            if not self.ner_pipeline or not text.strip():
                                return {"error": "Model yÃ¼klÃ¼ deÄŸil veya metin boÅŸ"}

                            try:
                                # NER model testi
                                results = self.ner_pipeline(text)
                                ner_results = []
                                for r in results:
                                    if r['score'] >= conf_threshold:
                                        entity_type = self.map_model_label_to_type(r['entity_group'])
                                        original_word = r['word']

                                        # Custom Lists'ten deÄŸiÅŸtirme Ã¼ret
                                        replacement = self.generate_text_with_exact_length(
                                            len(original_word), entity_type, original_word
                                        )

                                        ner_results.append({
                                            'method': 'NER_Model',
                                            'entity': entity_type,
                                            'word': original_word,
                                            'replacement': replacement,
                                            'score': round(r['score'], 3),
                                            'start': r['start'],
                                            'end': r['end'],
                                            'original_label': r['entity_group'],
                                            'custom_lists_used': entity_type in self.organized_data and len(
                                                original_word) in self.organized_data.get(entity_type, {})
                                        })

                                # TC kimlik regex testi
                                tc_pattern = r'\b[1-9][0-9]{9}[02468]\b'
                                tc_results = []
                                for match in re.finditer(tc_pattern, text):
                                    tc_no = match.group()
                                    if self.validate_turkish_id(tc_no):
                                        replacement = self.generate_text_with_exact_length(
                                            len(tc_no), 'tc_kimlik', tc_no
                                        )
                                        tc_results.append({
                                            'method': 'Regex_TC',
                                            'entity': 'tc_kimlik',
                                            'word': tc_no,
                                            'replacement': replacement,
                                            'score': 0.95,
                                            'start': match.start(),
                                            'end': match.end(),
                                            'validation': 'Valid',
                                            'custom_lists_used': False  # TC iÃ§in regex kullanÄ±lÄ±yor
                                        })

                                all_results = ner_results + tc_results
                                custom_lists_count = sum(1 for r in all_results if r.get('custom_lists_used', False))

                                return {
                                    "total_entities": len(all_results),
                                    "ner_entities": len(ner_results),
                                    "tc_entities": len(tc_results),
                                    "custom_lists_usage": custom_lists_count,
                                    "results": all_results
                                }
                            except Exception as e:
                                return {"error": str(e)}

                        test_btn.click(
                            test_model_with_custom_lists,
                            inputs=[test_text, test_confidence],
                            outputs=test_results
                        )

                    # ------------------ GeÃ§miÅŸ ------------------
                    with gr.TabItem("ðŸ—‚ï¸ GeÃ§miÅŸ"):
                        gr.Markdown("Son iÅŸlemlerin Ã¶zeti (Custom Lists kullanÄ±m bilgileri dahil).")
                        history_df = gr.Dataframe(interactive=False)
                        refresh_btn = gr.Button("ðŸ”„ Yenile")

                        def _load_history():
                            return self.get_processing_history()

                        refresh_btn.click(_load_history, inputs=None, outputs=history_df)
                        interface.load(_load_history, inputs=None, outputs=history_df)

                    # ------------------ YardÄ±m ------------------
                    with gr.TabItem("â“ YardÄ±m"):
                        gr.Markdown(f"""
    ### ðŸ¤– Enhanced NER Model + Custom Lists Bilgileri
    - **Model Yolu**: `{self.model_path}`
    - **Model Durumu**: {'âœ… YÃ¼klendi ve hazÄ±r' if self.ner_pipeline else 'âŒ YÃ¼klenemedi'}
    - **Veri KaynaÄŸÄ±**: Custom Lists (datalar.py)
    - **Toplam Veri**: {total_samples} Ã¶rnek
    - **Ä°ÅŸlem YÃ¶ntemi**: Font Ã¶zelliklerini koruyarak deÄŸiÅŸtirme

    ### ðŸ—‚ï¸ Custom Lists Ã–zellikleri
    - **Tam Karakter EÅŸleÅŸtirme**: Orijinal metin uzunluÄŸuyla aynÄ± uzunlukta veriler tercih edilir
    - **Uzunluk BazlÄ± Organizasyon**: Her entity tÃ¼rÃ¼ iÃ§in farklÄ± uzunluklarda Ã¶rnekler
    - **TutarlÄ± SeÃ§im**: AynÄ± orijinal metin her zaman aynÄ± deÄŸerle deÄŸiÅŸtirilir
    - **AkÄ±llÄ± Fallback**: Uygun uzunluk bulunamadÄ±ÄŸÄ±nda yakÄ±n uzunluklar denenir

    ### ðŸ“‹ Desteklenen Entity Tipleri & Custom Lists

    **NER Model ile Tespit + Custom Lists DeÄŸiÅŸtirme:**
    - **Ad Soyad** (`ad_soyad`): {sum(len(samples) for samples in self.organized_data.get('ad_soyad', {}).values())} Ã¶rnek
    - **Telefon** (`telefon`): {sum(len(samples) for samples in self.organized_data.get('telefon', {}).values())} Ã¶rnek  
    - **E-posta** (`email`): {sum(len(samples) for samples in self.organized_data.get('email', {}).values())} Ã¶rnek
    - **Adres** (`adres`): {sum(len(samples) for samples in self.organized_data.get('adres', {}).values())} Ã¶rnek
    - **Åžirket** (`sirket`): {sum(len(samples) for samples in self.organized_data.get('sirket', {}).values())} Ã¶rnek
    - **Para** (`para`): {sum(len(samples) for samples in self.organized_data.get('para', {}).values())} Ã¶rnek
    - **Tarih** (`tarih`): {sum(len(samples) for samples in self.organized_data.get('tarih', {}).values())} Ã¶rnek
    - **IBAN** (`iban`): {sum(len(samples) for samples in self.organized_data.get('iban', {}).values())} Ã¶rnek

    **Regex ile Tespit + GeÃ§erli Ãœretim:**
    - **TC Kimlik** (`tc_kimlik`): Regex tespiti + matemartiksel doÄŸrulama + yeni geÃ§erli TC Ã¼retimi

    ### ðŸ” Karakter EÅŸleÅŸtirme Ã–rnekleri (Custom Lists)
    ```
    Orijinal: "BÄ°M" (3 karakter)
    Custom Lists'te 3 karakterli markalar: ["ÅžOK", "A101", "MÄ°M"]
    SeÃ§ilen: "ÅžOK" (deterministik)

    Orijinal: "Ahmet YÄ±lmaz" (12 karakter)  
    Custom Lists'te 12 karakterli isimler: ["Mehmet Demir", "Fatma Ã–zkan", ...]
    SeÃ§ilen: "Mehmet Demir" (aynÄ± seed iÃ§in her zaman aynÄ±)
    ```

    ### ðŸ”„ TutarlÄ±lÄ±k Garantisi
    - **BÄ°M** ilk Ã¶rnekte **ÅžOK** ile deÄŸiÅŸtirildiyse, metin iÃ§inde tekrar geÃ§erse yine **ÅžOK** olur
    - **Ahmet** ilk Ã¶rnekte **Mehmet** ile deÄŸiÅŸtirildiyse, her yerde **Mehmet** olur
    - Seed deÄŸer (orijinal metin) aynÄ± olduÄŸu sÃ¼rece aynÄ± deÄŸiÅŸtirme yapÄ±lÄ±r

    ### ðŸš¨ Ã–nemli Notlar
    1. **Custom Lists Ã–nceliÄŸi**: Ã–nce custom lists'ten tam uzunlukta arama yapÄ±lÄ±r
    2. **YakÄ±n Uzunluk Denemesi**: Tam uzunluk bulunamazsa yakÄ±n uzunluklar denenir
    3. **Generic Fallback**: HiÃ§bir uygun veri bulunamadÄ±ÄŸÄ±nda anlamlÄ± generic deÄŸer Ã¼retilir
    4. **TC Kimlik Ã–zel**: TC kimlik iÃ§in regex + matematiksel doÄŸrulama + yeni geÃ§erli Ã¼retim
    5. **Karakter Koruma**: Orijinal uzunluk her zaman korunur
    6. **Font Koruma**: PDF'te font boyutu ve renk korunur
                        """)

                return interface


if __name__ == "__main__":
    app = EnhancedAnonymizationApp()
    demo = app.create_enhanced_interface()
    demo.launch(server_name="0.0.0.0", server_port=7860, show_error=True)